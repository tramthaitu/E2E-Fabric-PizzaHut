{"cells":[{"cell_type":"code","execution_count":1,"id":"6609d790-edee-4515-804e-4c4f7167e90c","metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"outputs":[{"data":{"application/vnd.livy.statement-meta+json":{"execution_finish_time":"2025-11-23T14:10:56.1323932Z","execution_start_time":"2025-11-23T14:10:55.6074418Z","livy_statement_state":"available","normalized_state":"finished","parent_msg_id":"6518c768-f729-4cdf-8624-77e05c238a83","queued_time":"2025-11-23T14:10:43.5039447Z","session_id":"a88cf86e-dea1-4f0b-8448-815c576e7969","session_start_time":"2025-11-23T14:10:43.5054519Z","spark_pool":null,"state":"finished","statement_id":3,"statement_ids":[3]},"text/plain":["StatementMeta(, a88cf86e-dea1-4f0b-8448-815c576e7969, 3, Finished, Available, Finished)"]},"metadata":{},"output_type":"display_data"}],"source":["# # Power BI Fabric Metadata Extraction Pipeline\n","\n","# ## Overview\n","# # This notebook extracts comprehensive metadata from Microsoft Fabric workspaces including semantic models, reports, measures, tables, columns, relationships, security roles, and refresh history.\n","\n","# ## Prerequisites\n","# - Access to Microsoft Fabric workspace\n","# - Required Python packages: `sempy`, `duckdb`, `pandas`, `pytz`\n","\n","# ## Installation\n","# Run the following cell to install required dependencies:"]},{"cell_type":"code","execution_count":2,"id":"83a878b4","metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"outputs":[{"data":{"application/vnd.livy.statement-meta+json":{"execution_finish_time":"2025-11-23T14:11:11.096239Z","execution_start_time":"2025-11-23T14:10:56.1349577Z","livy_statement_state":"available","normalized_state":"finished","parent_msg_id":"fcc526fd-41fe-4907-83dc-a24ce96dccce","queued_time":"2025-11-23T14:10:43.5068327Z","session_id":"a88cf86e-dea1-4f0b-8448-815c576e7969","session_start_time":null,"spark_pool":null,"state":"finished","statement_id":4,"statement_ids":[4]},"text/plain":["StatementMeta(, a88cf86e-dea1-4f0b-8448-815c576e7969, 4, Finished, Available, Finished)"]},"metadata":{},"output_type":"display_data"}],"source":["!pip install duckdb -q"]},{"cell_type":"code","execution_count":3,"id":"8e4459e7-cb6e-48a6-bcd6-53a85968e9e1","metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"outputs":[{"data":{"application/vnd.livy.statement-meta+json":{"execution_finish_time":"2025-11-23T14:11:14.8646017Z","execution_start_time":"2025-11-23T14:11:11.099088Z","livy_statement_state":"available","normalized_state":"finished","parent_msg_id":"7e1f22b8-f1ad-416c-9df6-8b8a63d2bd81","queued_time":"2025-11-23T14:10:43.5096452Z","session_id":"a88cf86e-dea1-4f0b-8448-815c576e7969","session_start_time":null,"spark_pool":null,"state":"finished","statement_id":5,"statement_ids":[5]},"text/plain":["StatementMeta(, a88cf86e-dea1-4f0b-8448-815c576e7969, 5, Finished, Available, Finished)"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["üìÖ Extraction Period: 2025-11-09 to 2025-11-23\n","üïê Current Timestamp: 2025-11-23 21:11:14\n","üìä Month ID: 202511\n"]}],"source":["# Import required libraries\n","import sempy.fabric as fabric\n","import duckdb\n","import pandas as pd\n","import pytz\n","import re\n","from datetime import datetime, timedelta\n","from notebookutils import mssparkutils\n","\n","# Configure timezone and date parameters\n","vn_tz = pytz.timezone('Asia/Ho_Chi_Minh')\n","time_now = datetime.now(vn_tz)\n","Previous_Date = (time_now - timedelta(days=14)).strftime(\"%Y-%m-%d\")\n","Current_Date = time_now.strftime(\"%Y-%m-%d\")\n","Current_Datetime = time_now.strftime(\"%Y-%m-%d %H:%M:%S\")\n","Current_MonthID = int(time_now.strftime(\"%Y%m\"))\n","\n","print(f\"üìÖ Extraction Period: {Previous_Date} to {Current_Date}\")\n","print(f\"üïê Current Timestamp: {Current_Datetime}\")\n","print(f\"üìä Month ID: {Current_MonthID}\")"]},{"cell_type":"markdown","id":"076b961c","metadata":{},"source":["## Configuration & Initialization\n","\n","This section imports required libraries and sets up timezone configurations for Vietnam (UTC+7). It establishes date ranges for data extraction:\n","- **Previous_Date**: 14 days before current date (for refresh history)\n","- **Current_Date**: Today's date\n","- **Current_Datetime**: Current timestamp for audit trails\n","- **Current_MonthID**: Year-month identifier (YYYYMM format)"]},{"cell_type":"markdown","id":"ac89fd28-4d75-4f2a-b884-15b9e1bc3229","metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"},"nteract":{"transient":{"deleting":false}}},"source":["## 1. Semantic Model Metadata Extraction\n","\n","### Purpose\n","Extract metadata about all semantic models (datasets) in specified workspaces.\n","\n","### Output Fields\n","- **YearMonth**: Reporting period identifier\n","- **WorkspaceID**: Unique workspace identifier\n","- **WorkspaceName**: Human-readable workspace name\n","- **DatasetID**: Unique semantic model identifier\n","- **DatasetName**: Semantic model name\n","- **CreatedTimestamp**: Dataset creation date\n","- **LastUpdate**: Last modification timestamp\n","- **ImportTime**: Metadata extraction timestamp\n","\n","### Business Value\n","Provides inventory of all semantic models for governance, usage tracking, and lifecycle management."]},{"cell_type":"code","execution_count":4,"id":"87523203-b8a2-4f8e-89a5-3fe8e10c84d8","metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"outputs":[{"data":{"application/vnd.livy.statement-meta+json":{"execution_finish_time":"2025-11-23T14:11:27.4666169Z","execution_start_time":"2025-11-23T14:11:14.8677577Z","livy_statement_state":"available","normalized_state":"finished","parent_msg_id":"6b208af9-28fa-47f4-98cc-a7672488e115","queued_time":"2025-11-23T14:10:43.5123021Z","session_id":"a88cf86e-dea1-4f0b-8448-815c576e7969","session_start_time":null,"spark_pool":null,"state":"finished","statement_id":6,"statement_ids":[6]},"text/plain":["StatementMeta(, a88cf86e-dea1-4f0b-8448-815c576e7969, 6, Finished, Available, Finished)"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["üîç Processing 1 workspace(s): Fabric & Dagster\n","  [1] Extracting from 'Fabric & Dagster'...\n","‚úÖ Extracted 3 semantic model(s)\n","\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>YearMonth</th>\n","      <th>WorkspaceID</th>\n","      <th>WorkspaceName</th>\n","      <th>DatasetID</th>\n","      <th>DatasetName</th>\n","      <th>CreatedTimestamp</th>\n","      <th>LastUpdate</th>\n","      <th>ImportTime</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>202511</td>\n","      <td>abf1b960-d04c-4434-9a4d-a84d961dbdad</td>\n","      <td>Fabric &amp; Dagster</td>\n","      <td>1b46bd95-8778-4ed7-a36c-4582c4dbae62</td>\n","      <td>FabricDagsterK1</td>\n","      <td>2025-09-28 13:48:07</td>\n","      <td>NaT</td>\n","      <td>2025-11-23 21:11:14</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>202511</td>\n","      <td>abf1b960-d04c-4434-9a4d-a84d961dbdad</td>\n","      <td>Fabric &amp; Dagster</td>\n","      <td>27bee6e7-ed0b-44d0-a80b-d64090e7ddc4</td>\n","      <td>FabircDagsterK1-Cloud</td>\n","      <td>2021-02-12 23:00:58</td>\n","      <td>NaT</td>\n","      <td>2025-11-23 21:11:14</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>202511</td>\n","      <td>abf1b960-d04c-4434-9a4d-a84d961dbdad</td>\n","      <td>Fabric &amp; Dagster</td>\n","      <td>26ce789d-54a1-4ded-bdc9-de65897d2f8e</td>\n","      <td>Dashboard</td>\n","      <td>2021-02-12 23:00:58</td>\n","      <td>NaT</td>\n","      <td>2025-11-23 21:11:14</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   YearMonth                           WorkspaceID     WorkspaceName  \\\n","0     202511  abf1b960-d04c-4434-9a4d-a84d961dbdad  Fabric & Dagster   \n","1     202511  abf1b960-d04c-4434-9a4d-a84d961dbdad  Fabric & Dagster   \n","2     202511  abf1b960-d04c-4434-9a4d-a84d961dbdad  Fabric & Dagster   \n","\n","                              DatasetID            DatasetName  \\\n","0  1b46bd95-8778-4ed7-a36c-4582c4dbae62        FabricDagsterK1   \n","1  27bee6e7-ed0b-44d0-a80b-d64090e7ddc4  FabircDagsterK1-Cloud   \n","2  26ce789d-54a1-4ded-bdc9-de65897d2f8e              Dashboard   \n","\n","     CreatedTimestamp LastUpdate          ImportTime  \n","0 2025-09-28 13:48:07        NaT 2025-11-23 21:11:14  \n","1 2021-02-12 23:00:58        NaT 2025-11-23 21:11:14  \n","2 2021-02-12 23:00:58        NaT 2025-11-23 21:11:14  "]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["# Define target workspaces\n","select_workspace = [\"Fabric & Dagster\"]\n","\n","# Get workspace information\n","workspaces = fabric.list_workspaces()\n","workspaces = workspaces[workspaces['Name'].isin(select_workspace)].reset_index(drop=True)\n","\n","print(f\"üîç Processing {len(workspaces)} workspace(s): {', '.join(workspaces['Name'].tolist())}\")\n","\n","# Extract semantic model metadata\n","metadata_semantic_model = pd.DataFrame()\n","\n","for idx, (_, row) in enumerate(workspaces.iterrows(), 1):\n","    workspace_id = row['Id']\n","    workspace_name = row['Name']\n","    \n","    print(f\"  [{idx}] Extracting from '{workspace_name}'...\")\n","    \n","    semantic_model = fabric.list_datasets(workspace=workspace_name)\n","    \n","    # Transform data using DuckDB for efficient processing\n","    semantic_model = duckdb.query(f'''\n","        SELECT\n","            {Current_MonthID} AS YearMonth,\n","            '{workspace_id}' AS WorkspaceID,\n","            '{workspace_name}' AS WorkspaceName,\n","            \"Dataset ID\" AS DatasetID,\n","            \"Dataset Name\" AS DatasetName,\n","            \"Created Timestamp\" AS CreatedTimestamp,\n","            \"Last Update\" AS LastUpdate,\n","            CAST('{Current_Datetime}' AS TIMESTAMP) AS ImportTime\n","        FROM semantic_model\n","    ''').to_df()\n","    \n","    metadata_semantic_model = pd.concat([metadata_semantic_model, semantic_model], ignore_index=True)\n","\n","print(f\"‚úÖ Extracted {len(metadata_semantic_model)} semantic model(s)\\n\")\n","metadata_semantic_model.head(5)"]},{"cell_type":"markdown","id":"ad28e69a-235f-4c1d-aa72-b99056ffa3c5","metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"},"nteract":{"transient":{"deleting":false}}},"source":["## 2. Report Metadata Extraction\n","\n","### Purpose\n","Extract metadata about Power BI reports and link them to their underlying semantic models.\n","\n","### Output Fields\n","- **YearMonth**: Reporting period\n","- **WorkspaceName**: Workspace containing the report\n","- **DatasetID/DatasetName**: Associated semantic model\n","- **DatasetCreatedTime**: When the underlying dataset was created\n","- **LastUpdate**: Dataset last refresh time\n","- **ReportID/ReportName**: Report identifiers\n","- **WebUrl**: Direct link to view report\n","- **EmbedUrl**: URL for embedding report\n","- **ImportTime**: Metadata extraction timestamp\n","\n","### Business Value\n","Maps reports to datasets for impact analysis, access tracking, and content governance."]},{"cell_type":"code","execution_count":5,"id":"06301415-acd4-4039-988f-b592027bd272","metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"outputs":[{"data":{"application/vnd.livy.statement-meta+json":{"execution_finish_time":"2025-11-23T14:11:27.8425032Z","execution_start_time":"2025-11-23T14:11:27.4698334Z","livy_statement_state":"available","normalized_state":"finished","parent_msg_id":"551df771-7c04-4375-aa1b-52d68096df17","queued_time":"2025-11-23T14:10:43.5152299Z","session_id":"a88cf86e-dea1-4f0b-8448-815c576e7969","session_start_time":null,"spark_pool":null,"state":"finished","statement_id":7,"statement_ids":[7]},"text/plain":["StatementMeta(, a88cf86e-dea1-4f0b-8448-815c576e7969, 7, Finished, Available, Finished)"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["  [1] Extracting reports from 'Fabric & Dagster'...\n","‚úÖ Extracted 4 report(s)\n","\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>YearMonth</th>\n","      <th>WorkspaceName</th>\n","      <th>DatasetID</th>\n","      <th>DatasetName</th>\n","      <th>DatasetCreatedTime</th>\n","      <th>LastUpdate</th>\n","      <th>ReportID</th>\n","      <th>ReportName</th>\n","      <th>WebUrl</th>\n","      <th>EmbedUrl</th>\n","      <th>ImportTime</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>202511</td>\n","      <td>Fabric &amp; Dagster</td>\n","      <td>1b46bd95-8778-4ed7-a36c-4582c4dbae62</td>\n","      <td>FabricDagsterK1</td>\n","      <td>2025-09-28 13:48:07</td>\n","      <td>NaT</td>\n","      <td>b7ee4aa5-3171-4889-b26d-a04318743915</td>\n","      <td>FabricDagsterK1</td>\n","      <td>https://app.powerbi.com/groups/abf1b960-d04c-4...</td>\n","      <td>https://app.powerbi.com/reportEmbed?reportId=b...</td>\n","      <td>2025-11-23 21:11:14</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>202511</td>\n","      <td>Fabric &amp; Dagster</td>\n","      <td>27bee6e7-ed0b-44d0-a80b-d64090e7ddc4</td>\n","      <td>FabircDagsterK1-Cloud</td>\n","      <td>2021-02-12 23:00:58</td>\n","      <td>NaT</td>\n","      <td>c2e4d7a0-2fda-42e6-9f61-c3a13bb5fed8</td>\n","      <td>Fabirc &amp; Dagster K1 - Cloud</td>\n","      <td>https://app.powerbi.com/groups/abf1b960-d04c-4...</td>\n","      <td>https://app.powerbi.com/reportEmbed?reportId=c...</td>\n","      <td>2025-11-23 21:11:14</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>202511</td>\n","      <td>Fabric &amp; Dagster</td>\n","      <td>26ce789d-54a1-4ded-bdc9-de65897d2f8e</td>\n","      <td>Dashboard</td>\n","      <td>2021-02-12 23:00:58</td>\n","      <td>NaT</td>\n","      <td>7c5ca77a-03aa-4380-a96d-ca1d688d1d0d</td>\n","      <td>Dashboard</td>\n","      <td>https://app.powerbi.com/groups/abf1b960-d04c-4...</td>\n","      <td>https://app.powerbi.com/reportEmbed?reportId=7...</td>\n","      <td>2025-11-23 21:11:14</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>202511</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>NaT</td>\n","      <td>NaT</td>\n","      <td>189091a9-74e8-434d-a5ea-4bcb9fed68ab</td>\n","      <td>Report Usage Metrics Report</td>\n","      <td>https://app.powerbi.com/groups/abf1b960-d04c-4...</td>\n","      <td>https://app.powerbi.com/reportEmbed?reportId=1...</td>\n","      <td>2025-11-23 21:11:14</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   YearMonth     WorkspaceName                             DatasetID  \\\n","0     202511  Fabric & Dagster  1b46bd95-8778-4ed7-a36c-4582c4dbae62   \n","1     202511  Fabric & Dagster  27bee6e7-ed0b-44d0-a80b-d64090e7ddc4   \n","2     202511  Fabric & Dagster  26ce789d-54a1-4ded-bdc9-de65897d2f8e   \n","3     202511              None                                  None   \n","\n","             DatasetName  DatasetCreatedTime LastUpdate  \\\n","0        FabricDagsterK1 2025-09-28 13:48:07        NaT   \n","1  FabircDagsterK1-Cloud 2021-02-12 23:00:58        NaT   \n","2              Dashboard 2021-02-12 23:00:58        NaT   \n","3                   None                 NaT        NaT   \n","\n","                               ReportID                   ReportName  \\\n","0  b7ee4aa5-3171-4889-b26d-a04318743915              FabricDagsterK1   \n","1  c2e4d7a0-2fda-42e6-9f61-c3a13bb5fed8  Fabirc & Dagster K1 - Cloud   \n","2  7c5ca77a-03aa-4380-a96d-ca1d688d1d0d                    Dashboard   \n","3  189091a9-74e8-434d-a5ea-4bcb9fed68ab  Report Usage Metrics Report   \n","\n","                                              WebUrl  \\\n","0  https://app.powerbi.com/groups/abf1b960-d04c-4...   \n","1  https://app.powerbi.com/groups/abf1b960-d04c-4...   \n","2  https://app.powerbi.com/groups/abf1b960-d04c-4...   \n","3  https://app.powerbi.com/groups/abf1b960-d04c-4...   \n","\n","                                            EmbedUrl          ImportTime  \n","0  https://app.powerbi.com/reportEmbed?reportId=b... 2025-11-23 21:11:14  \n","1  https://app.powerbi.com/reportEmbed?reportId=c... 2025-11-23 21:11:14  \n","2  https://app.powerbi.com/reportEmbed?reportId=7... 2025-11-23 21:11:14  \n","3  https://app.powerbi.com/reportEmbed?reportId=1... 2025-11-23 21:11:14  "]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["metadata_report = pd.DataFrame()\n","\n","for idx, (_, row) in enumerate(workspaces.iterrows(), 1):\n","    workspace_id = row['Id']\n","    workspace_name = row['Name']\n","    \n","    print(f\"  [{idx}] Extracting reports from '{workspace_name}'...\")\n","    \n","    list_reports = fabric.list_reports(workspace=workspace_name)\n","    \n","    # Join reports with semantic models\n","    power_bi_reports = duckdb.query(f'''\n","        SELECT\n","            {Current_MonthID} AS YearMonth,\n","            b.WorkspaceName,\n","            b.DatasetID,\n","            b.DatasetName, \n","            b.CreatedTimestamp AS DatasetCreatedTime,\n","            b.LastUpdate,\n","            a.Id AS ReportID,\n","            a.Name AS ReportName,\n","            a.\"Web Url\" AS WebUrl,\n","            a.\"Embed Url\" AS EmbedUrl,\n","            CAST('{Current_Datetime}' AS TIMESTAMP) AS ImportTime\n","        FROM list_reports a \n","        LEFT JOIN metadata_semantic_model b \n","            ON a.\"Dataset Id\" = b.DatasetID\n","    ''').to_df()\n","    \n","    metadata_report = pd.concat([metadata_report, power_bi_reports], ignore_index=True)\n","\n","print(f\"‚úÖ Extracted {len(metadata_report)} report(s)\\n\")\n","metadata_report.head(5)"]},{"cell_type":"markdown","id":"edb9a851-fe0e-4558-81e6-3f5c531a1012","metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"},"nteract":{"transient":{"deleting":false}}},"source":["## 3. Measures Metadata Extraction\n","\n","### Purpose\n","Extract all DAX measures from semantic models for documentation and lineage analysis.\n","\n","### Output Fields\n","- **YearMonth**: Reporting period\n","- **DatasetID**: Parent semantic model\n","- **Measure**: Measure name\n","- **Expression**: DAX formula\n","- **Description**: Measure documentation\n","- **Display Folder**: Organization folder\n","- **Format String**: Number/date formatting\n","- **Data Category**: Semantic type\n","- **ImportTime**: Extraction timestamp\n","\n","### Business Value\n","Enables measure documentation, DAX formula auditing, and business logic tracking across models."]},{"cell_type":"code","execution_count":21,"id":"dcc35a3c-6b91-4df5-b5cd-f6e1175b57a6","metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"outputs":[{"data":{"application/vnd.livy.statement-meta+json":{"execution_finish_time":"2025-11-23T14:15:32.5643571Z","execution_start_time":"2025-11-23T14:15:32.2026769Z","livy_statement_state":"available","normalized_state":"finished","parent_msg_id":"cd7d141f-5c3e-4d13-b672-20d5309337cf","queued_time":"2025-11-23T14:15:32.2009015Z","session_id":"a88cf86e-dea1-4f0b-8448-815c576e7969","session_start_time":null,"spark_pool":null,"state":"finished","statement_id":23,"statement_ids":[23]},"text/plain":["StatementMeta(, a88cf86e-dea1-4f0b-8448-815c576e7969, 23, Finished, Available, Finished)"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["  [1/3] Processing measures in 'FabricDagsterK1'...\n","  [2/3] Processing measures in 'FabircDagsterK1-Cloud'...\n","  [3/3] Processing measures in 'Dashboard'...\n","‚úÖ Extracted 9 measure(s) from 3 dataset(s)\n","\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>YearMonth</th>\n","      <th>DatasetID</th>\n","      <th>TableName</th>\n","      <th>MeasureName</th>\n","      <th>MeasureExpression</th>\n","      <th>MeasureDataType</th>\n","      <th>MeasureHidden</th>\n","      <th>MeasureDisplayFolder</th>\n","      <th>MeasureDescription</th>\n","      <th>FormatString</th>\n","      <th>DataCategory</th>\n","      <th>DetailRowsDefinition</th>\n","      <th>FormatStringDefinition</th>\n","      <th>ImportTime</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>202511</td>\n","      <td>1b46bd95-8778-4ed7-a36c-4582c4dbae62</td>\n","      <td>All Measures</td>\n","      <td>Measure</td>\n","      <td>123</td>\n","      <td>Int64</td>\n","      <td>False</td>\n","      <td></td>\n","      <td></td>\n","      <td>0</td>\n","      <td></td>\n","      <td>&lt;NA&gt;</td>\n","      <td>&lt;NA&gt;</td>\n","      <td>2025-11-23 21:11:14</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>202511</td>\n","      <td>27bee6e7-ed0b-44d0-a80b-d64090e7ddc4</td>\n","      <td>All Measures</td>\n","      <td>Salas Amount</td>\n","      <td>SUMX(F_Sales,[Amount])</td>\n","      <td>Double</td>\n","      <td>False</td>\n","      <td></td>\n","      <td></td>\n","      <td>#,0</td>\n","      <td></td>\n","      <td>&lt;NA&gt;</td>\n","      <td>&lt;NA&gt;</td>\n","      <td>2025-11-23 21:11:14</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>202511</td>\n","      <td>27bee6e7-ed0b-44d0-a80b-d64090e7ddc4</td>\n","      <td>All Measures</td>\n","      <td>Sales Target</td>\n","      <td>SUMX(F_Target,[Target])</td>\n","      <td>Int64</td>\n","      <td>False</td>\n","      <td></td>\n","      <td></td>\n","      <td>#,0</td>\n","      <td></td>\n","      <td>&lt;NA&gt;</td>\n","      <td>&lt;NA&gt;</td>\n","      <td>2025-11-23 21:11:14</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>202511</td>\n","      <td>27bee6e7-ed0b-44d0-a80b-d64090e7ddc4</td>\n","      <td>All Measures</td>\n","      <td>Openning Inventory</td>\n","      <td>SUMX(F_Inventory,[OpeningInventory])</td>\n","      <td>Int64</td>\n","      <td>False</td>\n","      <td></td>\n","      <td></td>\n","      <td>#,0</td>\n","      <td></td>\n","      <td>&lt;NA&gt;</td>\n","      <td>&lt;NA&gt;</td>\n","      <td>2025-11-23 21:11:14</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>202511</td>\n","      <td>27bee6e7-ed0b-44d0-a80b-d64090e7ddc4</td>\n","      <td>All Measures</td>\n","      <td>Closing Inventory</td>\n","      <td>SUMX(F_Inventory,[RemainingInventory])</td>\n","      <td>Int64</td>\n","      <td>False</td>\n","      <td></td>\n","      <td></td>\n","      <td>#,0</td>\n","      <td></td>\n","      <td>&lt;NA&gt;</td>\n","      <td>&lt;NA&gt;</td>\n","      <td>2025-11-23 21:11:14</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   YearMonth                             DatasetID     TableName  \\\n","0     202511  1b46bd95-8778-4ed7-a36c-4582c4dbae62  All Measures   \n","1     202511  27bee6e7-ed0b-44d0-a80b-d64090e7ddc4  All Measures   \n","2     202511  27bee6e7-ed0b-44d0-a80b-d64090e7ddc4  All Measures   \n","3     202511  27bee6e7-ed0b-44d0-a80b-d64090e7ddc4  All Measures   \n","4     202511  27bee6e7-ed0b-44d0-a80b-d64090e7ddc4  All Measures   \n","\n","          MeasureName                       MeasureExpression MeasureDataType  \\\n","0             Measure                                     123           Int64   \n","1        Salas Amount                  SUMX(F_Sales,[Amount])          Double   \n","2        Sales Target                 SUMX(F_Target,[Target])           Int64   \n","3  Openning Inventory    SUMX(F_Inventory,[OpeningInventory])           Int64   \n","4   Closing Inventory  SUMX(F_Inventory,[RemainingInventory])           Int64   \n","\n","   MeasureHidden MeasureDisplayFolder MeasureDescription FormatString  \\\n","0          False                                                    0   \n","1          False                                                  #,0   \n","2          False                                                  #,0   \n","3          False                                                  #,0   \n","4          False                                                  #,0   \n","\n","  DataCategory  DetailRowsDefinition  FormatStringDefinition  \\\n","0                               <NA>                    <NA>   \n","1                               <NA>                    <NA>   \n","2                               <NA>                    <NA>   \n","3                               <NA>                    <NA>   \n","4                               <NA>                    <NA>   \n","\n","           ImportTime  \n","0 2025-11-23 21:11:14  \n","1 2025-11-23 21:11:14  \n","2 2025-11-23 21:11:14  \n","3 2025-11-23 21:11:14  \n","4 2025-11-23 21:11:14  "]},"execution_count":68,"metadata":{},"output_type":"execute_result"}],"source":["metadata_measures = pd.DataFrame()\n","total_measures = 0\n","\n","for idx, (_, row) in enumerate(metadata_semantic_model.iterrows(), 1):\n","    workspace_name = row[\"WorkspaceName\"]\n","    dataset_name = row[\"DatasetName\"]\n","    dataset_id = row[\"DatasetID\"]\n","    \n","    print(f\"  [{idx}/{len(metadata_semantic_model)}] Processing measures in '{dataset_name}'...\")\n","    \n","    measures = fabric.list_measures(workspace=workspace_name, dataset=dataset_name)\n","    \n","    if len(measures) > 0:\n","        measures = duckdb.query(f'''\n","            SELECT\n","                {Current_MonthID} AS YearMonth,\n","                '{dataset_id}' AS DatasetID,\n","                a.*,\n","                CAST('{Current_Datetime}' AS TIMESTAMP) AS ImportTime\n","            FROM measures a \n","        ''').to_df()\n","        measures.columns = [re.sub(r' ', '', col) for col in measures.columns]\n","        metadata_measures = pd.concat([metadata_measures, measures], ignore_index=True)\n","        total_measures += len(measures)\n","\n","print(f\"‚úÖ Extracted {total_measures} measure(s) from {len(metadata_semantic_model)} dataset(s)\\n\")\n","metadata_measures.head(5)"]},{"cell_type":"markdown","id":"ab52c1d6-b7c8-45f9-88db-a674692d33ac","metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"},"nteract":{"transient":{"deleting":false}}},"source":["## 4. Table & Column Metadata Extraction\n","\n","### Purpose\n","Extract comprehensive schema information including tables, columns, and their properties.\n","\n","### Output Fields\n","- **YearMonth**: Reporting period\n","- **DatasetID**: Parent semantic model\n","- **TableName/TableType**: Table identification and type (Import/DirectQuery/Calculated)\n","- **TableQuery**: M/SQL query definition for the table\n","- **TableHidden/TableDescription**: Visibility and documentation\n","- **ColumnName/DataType**: Column schema information\n","- **ColumnHidden/ColumnDescription**: Column visibility and documentation\n","- **FormatString**: Display formatting\n","- **Source**: Column source expression\n","- **DisplayFolder**: Organizational structure\n","- **ModifiedTime**: Last modification timestamp\n","- **ImportTime**: Extraction timestamp\n","\n","### Business Value\n","Provides complete data model schema for documentation, impact analysis, and data catalog integration."]},{"cell_type":"code","execution_count":7,"id":"3dcb6208-01d5-4afe-9d75-afcd0a5fd930","metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"outputs":[{"data":{"application/vnd.livy.statement-meta+json":{"execution_finish_time":"2025-11-23T14:11:39.0916893Z","execution_start_time":"2025-11-23T14:11:30.4299933Z","livy_statement_state":"available","normalized_state":"finished","parent_msg_id":"e259b30e-e084-4b3d-9fc3-00c895c842b9","queued_time":"2025-11-23T14:10:43.5206684Z","session_id":"a88cf86e-dea1-4f0b-8448-815c576e7969","session_start_time":null,"spark_pool":null,"state":"finished","statement_id":9,"statement_ids":[9]},"text/plain":["StatementMeta(, a88cf86e-dea1-4f0b-8448-815c576e7969, 9, Finished, Available, Finished)"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["  [1/3] Processing schema of 'FabricDagsterK1'...\n","  [2/3] Processing schema of 'FabircDagsterK1-Cloud'...\n","  [3/3] Processing schema of 'Dashboard'...\n","‚úÖ Extracted 220 column(s) from 10 table(s)\n","\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>YearMonth</th>\n","      <th>DatasetID</th>\n","      <th>TableName</th>\n","      <th>TableType</th>\n","      <th>TableQuery</th>\n","      <th>TableHidden</th>\n","      <th>TableDescription</th>\n","      <th>ColumnName</th>\n","      <th>ColumnType</th>\n","      <th>ColumnHidden</th>\n","      <th>ColumnDescription</th>\n","      <th>DataType</th>\n","      <th>FormatString</th>\n","      <th>Source</th>\n","      <th>DisplayFolder</th>\n","      <th>ModifiedTime</th>\n","      <th>ImportTime</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>202511</td>\n","      <td>1b46bd95-8778-4ed7-a36c-4582c4dbae62</td>\n","      <td>D_Customer</td>\n","      <td>Table</td>\n","      <td>let\\n    Source = Sql.Database(\"DESKTOP-P4K1FP...</td>\n","      <td>False</td>\n","      <td></td>\n","      <td>CustomerID</td>\n","      <td>Data</td>\n","      <td>False</td>\n","      <td></td>\n","      <td>Int64</td>\n","      <td>0</td>\n","      <td>CustomerID</td>\n","      <td></td>\n","      <td>2025-09-28 13:51:42</td>\n","      <td>2025-11-23 21:11:14</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>202511</td>\n","      <td>1b46bd95-8778-4ed7-a36c-4582c4dbae62</td>\n","      <td>D_Customer</td>\n","      <td>Table</td>\n","      <td>let\\n    Source = Sql.Database(\"DESKTOP-P4K1FP...</td>\n","      <td>False</td>\n","      <td></td>\n","      <td>CustomerName</td>\n","      <td>Data</td>\n","      <td>False</td>\n","      <td></td>\n","      <td>String</td>\n","      <td></td>\n","      <td>CustomerName</td>\n","      <td></td>\n","      <td>2025-09-28 13:48:58</td>\n","      <td>2025-11-23 21:11:14</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>202511</td>\n","      <td>1b46bd95-8778-4ed7-a36c-4582c4dbae62</td>\n","      <td>D_Customer</td>\n","      <td>Table</td>\n","      <td>let\\n    Source = Sql.Database(\"DESKTOP-P4K1FP...</td>\n","      <td>False</td>\n","      <td></td>\n","      <td>Email</td>\n","      <td>Data</td>\n","      <td>False</td>\n","      <td></td>\n","      <td>String</td>\n","      <td></td>\n","      <td>Email</td>\n","      <td></td>\n","      <td>2025-09-28 13:48:58</td>\n","      <td>2025-11-23 21:11:14</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>202511</td>\n","      <td>1b46bd95-8778-4ed7-a36c-4582c4dbae62</td>\n","      <td>D_Customer</td>\n","      <td>Table</td>\n","      <td>let\\n    Source = Sql.Database(\"DESKTOP-P4K1FP...</td>\n","      <td>False</td>\n","      <td></td>\n","      <td>BirthDate</td>\n","      <td>Data</td>\n","      <td>False</td>\n","      <td></td>\n","      <td>DateTime</td>\n","      <td>General Date</td>\n","      <td>BirthDate</td>\n","      <td></td>\n","      <td>2025-09-28 13:48:58</td>\n","      <td>2025-11-23 21:11:14</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>202511</td>\n","      <td>1b46bd95-8778-4ed7-a36c-4582c4dbae62</td>\n","      <td>D_Customer</td>\n","      <td>Table</td>\n","      <td>let\\n    Source = Sql.Database(\"DESKTOP-P4K1FP...</td>\n","      <td>False</td>\n","      <td></td>\n","      <td>Gender</td>\n","      <td>Data</td>\n","      <td>False</td>\n","      <td></td>\n","      <td>String</td>\n","      <td></td>\n","      <td>Gender</td>\n","      <td></td>\n","      <td>2025-09-28 13:48:58</td>\n","      <td>2025-11-23 21:11:14</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   YearMonth                             DatasetID   TableName TableType  \\\n","0     202511  1b46bd95-8778-4ed7-a36c-4582c4dbae62  D_Customer     Table   \n","1     202511  1b46bd95-8778-4ed7-a36c-4582c4dbae62  D_Customer     Table   \n","2     202511  1b46bd95-8778-4ed7-a36c-4582c4dbae62  D_Customer     Table   \n","3     202511  1b46bd95-8778-4ed7-a36c-4582c4dbae62  D_Customer     Table   \n","4     202511  1b46bd95-8778-4ed7-a36c-4582c4dbae62  D_Customer     Table   \n","\n","                                          TableQuery  TableHidden  \\\n","0  let\\n    Source = Sql.Database(\"DESKTOP-P4K1FP...        False   \n","1  let\\n    Source = Sql.Database(\"DESKTOP-P4K1FP...        False   \n","2  let\\n    Source = Sql.Database(\"DESKTOP-P4K1FP...        False   \n","3  let\\n    Source = Sql.Database(\"DESKTOP-P4K1FP...        False   \n","4  let\\n    Source = Sql.Database(\"DESKTOP-P4K1FP...        False   \n","\n","  TableDescription    ColumnName ColumnType  ColumnHidden ColumnDescription  \\\n","0                     CustomerID       Data         False                     \n","1                   CustomerName       Data         False                     \n","2                          Email       Data         False                     \n","3                      BirthDate       Data         False                     \n","4                         Gender       Data         False                     \n","\n","   DataType  FormatString        Source DisplayFolder        ModifiedTime  \\\n","0     Int64             0    CustomerID               2025-09-28 13:51:42   \n","1    String                CustomerName               2025-09-28 13:48:58   \n","2    String                       Email               2025-09-28 13:48:58   \n","3  DateTime  General Date     BirthDate               2025-09-28 13:48:58   \n","4    String                      Gender               2025-09-28 13:48:58   \n","\n","           ImportTime  \n","0 2025-11-23 21:11:14  \n","1 2025-11-23 21:11:14  \n","2 2025-11-23 21:11:14  \n","3 2025-11-23 21:11:14  \n","4 2025-11-23 21:11:14  "]},"execution_count":26,"metadata":{},"output_type":"execute_result"}],"source":["metadata_table_columns = pd.DataFrame()\n","total_columns = 0\n","\n","for idx, (_, row) in enumerate(metadata_semantic_model.iterrows(), 1):\n","    workspace_name = row[\"WorkspaceName\"]\n","    dataset_name = row[\"DatasetName\"]\n","    dataset_id = row[\"DatasetID\"]\n","    \n","    print(f\"  [{idx}/{len(metadata_semantic_model)}] Processing schema of '{dataset_name}'...\")\n","    \n","    tables = fabric.list_tables(workspace=workspace_name, dataset=dataset_name)\n","    \n","    if len(tables) > 0:\n","        # Get additional table metadata via DAX\n","        temp_tables = fabric.evaluate_dax(\n","            workspace=workspace_name, \n","            dataset=dataset_name, \n","            dax_string=\"EVALUATE INFO.TABLES()\"\n","        )\n","        partitions = fabric.evaluate_dax(\n","            workspace=workspace_name, \n","            dataset=dataset_name, \n","            dax_string=\"EVALUATE INFO.PARTITIONS()\"\n","        )\n","        \n","        # Clean column names\n","        temp_tables.columns = [re.sub(r'[\\[\\]]', '', col) for col in temp_tables.columns]\n","        partitions.columns = [re.sub(r'[\\[\\]]', '', col) for col in partitions.columns]\n","        \n","        # Get column metadata\n","        columns = fabric.list_columns(workspace=workspace_name, dataset=dataset_name)\n","        \n","        # Combine all metadata\n","        data_tables_columns = duckdb.query(f'''\n","            SELECT\n","                {Current_MonthID} AS YearMonth,\n","                '{dataset_id}' AS DatasetID,\n","                b.Name AS TableName,\n","                b.Type AS TableType,\n","                d.QueryDefinition AS TableQuery,\n","                b.Hidden AS TableHidden,\n","                b.Description AS TableDescription,\n","                a.\"Column Name\" AS ColumnName,\n","                a.Type AS ColumnType, \n","                a.Hidden AS ColumnHidden,\n","                a.Description AS ColumnDescription,\n","                a.\"Data Type\" AS DataType,\n","                a.\"Format String\" AS FormatString,\n","                a.Source,\n","                a.\"Display Folder\" AS DisplayFolder,\n","                a.\"Modified Time\" AS ModifiedTime,\n","                CAST('{Current_Datetime}' AS TIMESTAMP) AS ImportTime\n","            FROM columns a \n","            LEFT JOIN tables b ON a.\"Table Name\" = b.Name\n","            LEFT JOIN temp_tables c ON b.Name = c.Name\n","            LEFT JOIN partitions d ON c.ID = d.TableID\n","        ''').to_df()\n","        \n","        metadata_table_columns = pd.concat([metadata_table_columns, data_tables_columns], ignore_index=True)\n","        total_columns += len(columns)\n","\n","print(f\"‚úÖ Extracted {total_columns} column(s) from {len(tables)} table(s)\\n\")\n","metadata_table_columns.head(5)"]},{"cell_type":"markdown","id":"f1d0048c-aa0c-487d-9d37-786bb8297937","metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"},"nteract":{"transient":{"deleting":false}}},"source":["## 5. Relationship Metadata Extraction\n","\n","### Purpose\n","Extract table relationships to understand data model structure and dependencies.\n","\n","### Output Fields\n","- **YearMonth**: Reporting period\n","- **DatasetID**: Parent semantic model\n","- **From Table/Column**: Source side of relationship\n","- **To Table/Column**: Target side of relationship\n","- **Cross Filtering Behavior**: Single/Both direction filtering\n","- **Cardinality**: One-to-One, One-to-Many, Many-to-One\n","- **Is Active**: Whether relationship is active\n","- **Security Filtering Behavior**: How RLS applies\n","- **ImportTime**: Extraction timestamp\n","\n","### Business Value\n","Enables data lineage visualization, relationship validation, and impact analysis for model changes."]},{"cell_type":"code","execution_count":24,"id":"65a0e39b-be48-4de5-9a77-b074c173aebb","metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"outputs":[{"data":{"application/vnd.livy.statement-meta+json":{"execution_finish_time":"2025-11-23T14:16:59.1017625Z","execution_start_time":"2025-11-23T14:16:58.7451412Z","livy_statement_state":"available","normalized_state":"finished","parent_msg_id":"9f105a30-972c-4bf0-b1f3-c294e980a683","queued_time":"2025-11-23T14:16:58.7433801Z","session_id":"a88cf86e-dea1-4f0b-8448-815c576e7969","session_start_time":null,"spark_pool":null,"state":"finished","statement_id":26,"statement_ids":[26]},"text/plain":["StatementMeta(, a88cf86e-dea1-4f0b-8448-815c576e7969, 26, Finished, Available, Finished)"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["  [1/3] Extracting relationships from 'FabricDagsterK1'...\n","  [2/3] Extracting relationships from 'FabircDagsterK1-Cloud'...\n","  [3/3] Extracting relationships from 'Dashboard'...\n","‚úÖ Extracted 22 relationship(s)\n","\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>YearMonth</th>\n","      <th>DatasetID</th>\n","      <th>Multiplicity</th>\n","      <th>FromTable</th>\n","      <th>FromColumn</th>\n","      <th>ToTable</th>\n","      <th>ToColumn</th>\n","      <th>Active</th>\n","      <th>CrossFilteringBehavior</th>\n","      <th>SecurityFilteringBehavior</th>\n","      <th>JoinOnDateBehavior</th>\n","      <th>RelyOnReferentialIntegrity</th>\n","      <th>State</th>\n","      <th>ModifiedTime</th>\n","      <th>RelationshipName</th>\n","      <th>ImportTime</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>202511</td>\n","      <td>1b46bd95-8778-4ed7-a36c-4582c4dbae62</td>\n","      <td>m:1</td>\n","      <td>F_Target</td>\n","      <td>OutletID</td>\n","      <td>D_Outlet</td>\n","      <td>OutletID</td>\n","      <td>True</td>\n","      <td>OneDirection</td>\n","      <td>OneDirection</td>\n","      <td>DateAndTime</td>\n","      <td>False</td>\n","      <td>Ready</td>\n","      <td>2025-09-28 13:51:08</td>\n","      <td>4ba24d1f-f14a-6fda-f608-5d5371106111</td>\n","      <td>2025-11-23 21:11:14</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>202511</td>\n","      <td>1b46bd95-8778-4ed7-a36c-4582c4dbae62</td>\n","      <td>m:1</td>\n","      <td>F_Inventory</td>\n","      <td>OutletID</td>\n","      <td>D_Outlet</td>\n","      <td>OutletID</td>\n","      <td>True</td>\n","      <td>OneDirection</td>\n","      <td>OneDirection</td>\n","      <td>DateAndTime</td>\n","      <td>False</td>\n","      <td>Ready</td>\n","      <td>2025-09-28 13:51:12</td>\n","      <td>9aefa038-948b-9f22-7e76-ef7ffde5b26e</td>\n","      <td>2025-11-23 21:11:14</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>202511</td>\n","      <td>1b46bd95-8778-4ed7-a36c-4582c4dbae62</td>\n","      <td>m:1</td>\n","      <td>F_Sales</td>\n","      <td>OutletID</td>\n","      <td>D_Outlet</td>\n","      <td>OutletID</td>\n","      <td>True</td>\n","      <td>OneDirection</td>\n","      <td>OneDirection</td>\n","      <td>DateAndTime</td>\n","      <td>False</td>\n","      <td>Ready</td>\n","      <td>2025-09-28 13:51:23</td>\n","      <td>a2e0fcd8-3809-7708-f561-79af364e1354</td>\n","      <td>2025-11-23 21:11:14</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>202511</td>\n","      <td>1b46bd95-8778-4ed7-a36c-4582c4dbae62</td>\n","      <td>m:1</td>\n","      <td>F_Sales</td>\n","      <td>CustomerID</td>\n","      <td>D_Customer</td>\n","      <td>CustomerID</td>\n","      <td>True</td>\n","      <td>OneDirection</td>\n","      <td>OneDirection</td>\n","      <td>DateAndTime</td>\n","      <td>False</td>\n","      <td>Ready</td>\n","      <td>2025-09-28 13:51:42</td>\n","      <td>5a6fd39c-92cd-8201-29fe-a73edc669118</td>\n","      <td>2025-11-23 21:11:14</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>202511</td>\n","      <td>1b46bd95-8778-4ed7-a36c-4582c4dbae62</td>\n","      <td>m:1</td>\n","      <td>F_Sales</td>\n","      <td>StaffID</td>\n","      <td>D_Staff</td>\n","      <td>StaffID</td>\n","      <td>True</td>\n","      <td>OneDirection</td>\n","      <td>OneDirection</td>\n","      <td>DateAndTime</td>\n","      <td>False</td>\n","      <td>Ready</td>\n","      <td>2025-09-28 13:52:00</td>\n","      <td>9c3c51da-f5f0-8c71-0bb8-693c8db7fb91</td>\n","      <td>2025-11-23 21:11:14</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   YearMonth                             DatasetID Multiplicity    FromTable  \\\n","0     202511  1b46bd95-8778-4ed7-a36c-4582c4dbae62          m:1     F_Target   \n","1     202511  1b46bd95-8778-4ed7-a36c-4582c4dbae62          m:1  F_Inventory   \n","2     202511  1b46bd95-8778-4ed7-a36c-4582c4dbae62          m:1      F_Sales   \n","3     202511  1b46bd95-8778-4ed7-a36c-4582c4dbae62          m:1      F_Sales   \n","4     202511  1b46bd95-8778-4ed7-a36c-4582c4dbae62          m:1      F_Sales   \n","\n","   FromColumn     ToTable    ToColumn  Active CrossFilteringBehavior  \\\n","0    OutletID    D_Outlet    OutletID    True           OneDirection   \n","1    OutletID    D_Outlet    OutletID    True           OneDirection   \n","2    OutletID    D_Outlet    OutletID    True           OneDirection   \n","3  CustomerID  D_Customer  CustomerID    True           OneDirection   \n","4     StaffID     D_Staff     StaffID    True           OneDirection   \n","\n","  SecurityFilteringBehavior JoinOnDateBehavior  RelyOnReferentialIntegrity  \\\n","0              OneDirection        DateAndTime                       False   \n","1              OneDirection        DateAndTime                       False   \n","2              OneDirection        DateAndTime                       False   \n","3              OneDirection        DateAndTime                       False   \n","4              OneDirection        DateAndTime                       False   \n","\n","   State        ModifiedTime                      RelationshipName  \\\n","0  Ready 2025-09-28 13:51:08  4ba24d1f-f14a-6fda-f608-5d5371106111   \n","1  Ready 2025-09-28 13:51:12  9aefa038-948b-9f22-7e76-ef7ffde5b26e   \n","2  Ready 2025-09-28 13:51:23  a2e0fcd8-3809-7708-f561-79af364e1354   \n","3  Ready 2025-09-28 13:51:42  5a6fd39c-92cd-8201-29fe-a73edc669118   \n","4  Ready 2025-09-28 13:52:00  9c3c51da-f5f0-8c71-0bb8-693c8db7fb91   \n","\n","           ImportTime  \n","0 2025-11-23 21:11:14  \n","1 2025-11-23 21:11:14  \n","2 2025-11-23 21:11:14  \n","3 2025-11-23 21:11:14  \n","4 2025-11-23 21:11:14  "]},"execution_count":77,"metadata":{},"output_type":"execute_result"}],"source":["metadata_relationships = pd.DataFrame()\n","total_relationships = 0\n","\n","for idx, (_, row) in enumerate(metadata_semantic_model.iterrows(), 1):\n","    workspace_name = row[\"WorkspaceName\"]\n","    dataset_name = row[\"DatasetName\"]\n","    dataset_id = row[\"DatasetID\"]\n","    \n","    print(f\"  [{idx}/{len(metadata_semantic_model)}] Extracting relationships from '{dataset_name}'...\")\n","    \n","    relationships = fabric.list_relationships(workspace=workspace_name, dataset=dataset_name)\n"," \n","    if len(relationships) > 0:\n","        data_relationships = duckdb.query(f'''\n","            SELECT\n","                {Current_MonthID} AS YearMonth,\n","                '{dataset_id}' AS DatasetID,\n","                *,\n","                CAST('{Current_Datetime}' AS TIMESTAMP) AS ImportTime\n","            FROM relationships\n","        ''').to_df()\n","        data_relationships.columns = [re.sub(r' ', '', col) for col in data_relationships.columns]\n","        metadata_relationships = pd.concat([metadata_relationships, data_relationships], ignore_index=True)\n","        total_relationships += len(relationships)\n","\n","print(f\"‚úÖ Extracted {total_relationships} relationship(s)\\n\")\n","metadata_relationships.head(5)"]},{"cell_type":"markdown","id":"395e671f-43cd-4035-ae18-aa3007467ed3","metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"},"nteract":{"transient":{"deleting":false}}},"source":["## 6. Role & Member Metadata Extraction\n","\n","### Purpose\n","Extract Row-Level Security (RLS) roles and their member assignments for security auditing.\n","\n","### Output Fields\n","- **YearMonth**: Reporting period\n","- **RoleKey**: Unique role identifier (DatasetID-RoleID)\n","- **DatasetID**: Parent semantic model\n","- **RoleID**: Internal role identifier\n","- **RoleName**: Human-readable role name\n","- **RoleDescription**: Role purpose documentation\n","- **MemberName**: User/Group assigned to role\n","- **ImportTime**: Extraction timestamp\n","\n","### Business Value\n","Enables security auditing, access governance, and compliance reporting for data access controls."]},{"cell_type":"code","execution_count":34,"id":"5391d77f-b8ac-4b8e-bb5a-7c089a74f1bd","metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"outputs":[{"data":{"application/vnd.livy.statement-meta+json":{"execution_finish_time":"2025-11-23T14:26:30.1589331Z","execution_start_time":"2025-11-23T14:26:26.0900808Z","livy_statement_state":"available","normalized_state":"finished","parent_msg_id":"7a9b5632-bdb8-4fdc-912a-776bb1bdc3cb","queued_time":"2025-11-23T14:26:26.0883079Z","session_id":"a88cf86e-dea1-4f0b-8448-815c576e7969","session_start_time":null,"spark_pool":null,"state":"finished","statement_id":36,"statement_ids":[36]},"text/plain":["StatementMeta(, a88cf86e-dea1-4f0b-8448-815c576e7969, 36, Finished, Available, Finished)"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["  [1/3] Extracting roles from 'FabricDagsterK1'...\n","  [2/3] Extracting roles from 'FabircDagsterK1-Cloud'...\n","  [3/3] Extracting roles from 'Dashboard'...\n","‚úÖ Extracted 2 role member(s)\n","\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>YearMonth</th>\n","      <th>RoleKey</th>\n","      <th>DatasetID</th>\n","      <th>RoleID</th>\n","      <th>RoleName</th>\n","      <th>RoleDescription</th>\n","      <th>MemberName</th>\n","      <th>ImportTime</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>202511</td>\n","      <td>1b46bd95-8778-4ed7-a36c-4582c4dbae62-3978</td>\n","      <td>1b46bd95-8778-4ed7-a36c-4582c4dbae62</td>\n","      <td>3978</td>\n","      <td>View All</td>\n","      <td>No Description</td>\n","      <td>tu.thai.tram@8rc8vk.onmicrosoft.com</td>\n","      <td>2025-11-23 21:11:14</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>202511</td>\n","      <td>1b46bd95-8778-4ed7-a36c-4582c4dbae62-3978</td>\n","      <td>1b46bd95-8778-4ed7-a36c-4582c4dbae62</td>\n","      <td>3978</td>\n","      <td>View All</td>\n","      <td>No Description</td>\n","      <td>hoang.huy.nguyen@8rc8vk.onmicrosoft.com</td>\n","      <td>2025-11-23 21:11:14</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   YearMonth                                    RoleKey  \\\n","0     202511  1b46bd95-8778-4ed7-a36c-4582c4dbae62-3978   \n","1     202511  1b46bd95-8778-4ed7-a36c-4582c4dbae62-3978   \n","\n","                              DatasetID  RoleID  RoleName RoleDescription  \\\n","0  1b46bd95-8778-4ed7-a36c-4582c4dbae62    3978  View All  No Description   \n","1  1b46bd95-8778-4ed7-a36c-4582c4dbae62    3978  View All  No Description   \n","\n","                                MemberName          ImportTime  \n","0      tu.thai.tram@8rc8vk.onmicrosoft.com 2025-11-23 21:11:14  \n","1  hoang.huy.nguyen@8rc8vk.onmicrosoft.com 2025-11-23 21:11:14  "]},"execution_count":107,"metadata":{},"output_type":"execute_result"}],"source":["metadata_role_members = pd.DataFrame()\n","total_members = 0\n","\n","for idx, (_, row) in enumerate(metadata_semantic_model.iterrows(), 1):\n","    workspace_name = row[\"WorkspaceName\"]\n","    dataset_name = row[\"DatasetName\"]\n","    dataset_id = row[\"DatasetID\"]\n","    \n","    print(f\"  [{idx}/{len(metadata_semantic_model)}] Extracting roles from '{dataset_name}'...\")\n","    \n","    try:\n","        # Query role definitions\n","        roles = fabric.evaluate_dax(\n","            workspace=workspace_name,\n","            dataset=dataset_name,\n","            dax_string=\"SELECT * FROM $SYSTEM.TMSCHEMA_ROLES\"\n","        )\n","        \n","        # Query role memberships\n","        members = fabric.evaluate_dax(\n","            workspace=workspace_name,\n","            dataset=dataset_name,\n","            dax_string=\"SELECT * FROM $SYSTEM.TMSCHEMA_ROLE_MEMBERSHIPS\"\n","        )\n","        \n","        # Combine role and member information\n","        data_role_members = duckdb.query(f'''\n","            SELECT\n","                {Current_MonthID} AS YearMonth,\n","                '{dataset_id}' || '-' || CAST(a.RoleID AS VARCHAR) AS RoleKey,\n","                '{dataset_id}' AS DatasetID,\n","                a.RoleID,\n","                b.Name AS RoleName,\n","                COALESCE(b.Description, 'No Description') AS RoleDescription,\n","                a.MemberName,\n","                CAST('{Current_Datetime}' AS TIMESTAMP) AS ImportTime\n","            FROM members a \n","            LEFT JOIN roles b ON a.RoleID = b.ID\n","        ''').to_df()\n","        \n","        metadata_role_members = pd.concat([metadata_role_members, data_role_members], ignore_index=True)\n","        total_members += len(members)\n","        \n","    except Exception as e:\n","        print(f\"    ‚ö†Ô∏è  No roles found or access denied: {str(e)[:50]}\")\n","\n","print(f\"‚úÖ Extracted {total_members} role member(s)\\n\")\n","metadata_role_members.head(5)"]},{"cell_type":"markdown","id":"3d541d61-79a8-4271-a562-5d489565eb92","metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"},"nteract":{"transient":{"deleting":false}}},"source":["## 7. RLS Expression Extraction\n","\n","### Purpose\n","Extract Row-Level Security (RLS) filter expressions to document data access restrictions.\n","\n","### Output Fields\n","- **YearMonth**: Reporting period\n","- **WorkspaceID/WorkspaceName**: Workspace context\n","- **DatasetID/DatasetName**: Parent semantic model\n","- **RoleKey**: Unique role identifier\n","- **RoleID/RoleName**: Role identification\n","- **TableName**: Table with RLS filter\n","- **FilterExpression**: DAX filter expression\n","- **ImportTime**: Extraction timestamp\n","\n","### Business Value\n","Documents security logic for compliance, enables security auditing, and supports RLS testing/validation."]},{"cell_type":"code","execution_count":10,"id":"f6ed15c8-4c5e-4754-a046-23ea80fb19c6","metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"outputs":[{"data":{"application/vnd.livy.statement-meta+json":{"execution_finish_time":"2025-11-23T14:11:43.8404176Z","execution_start_time":"2025-11-23T14:11:43.4246864Z","livy_statement_state":"available","normalized_state":"finished","parent_msg_id":"0196ffd0-9120-4218-aeff-3fa0177451c1","queued_time":"2025-11-23T14:10:43.5291606Z","session_id":"a88cf86e-dea1-4f0b-8448-815c576e7969","session_start_time":null,"spark_pool":null,"state":"finished","statement_id":12,"statement_ids":[12]},"text/plain":["StatementMeta(, a88cf86e-dea1-4f0b-8448-815c576e7969, 12, Finished, Available, Finished)"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["  [1/3] Extracting RLS expressions from 'FabricDagsterK1'...\n","  [2/3] Extracting RLS expressions from 'FabircDagsterK1-Cloud'...\n","  [3/3] Extracting RLS expressions from 'Dashboard'...\n","‚úÖ Extracted 0 RLS expression(s)\n","\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["Empty DataFrame\n","Columns: []\n","Index: []"]},"execution_count":35,"metadata":{},"output_type":"execute_result"}],"source":["row_level_security_expression = pd.DataFrame()\n","total_rls_rules = 0\n","\n","for idx, (_, row) in enumerate(metadata_semantic_model.iterrows(), 1):\n","    workspace_id = row['WorkspaceID']\n","    workspace_name = row[\"WorkspaceName\"]\n","    dataset_name = row[\"DatasetName\"]\n","    dataset_id = row[\"DatasetID\"]\n","    \n","    print(f\"  [{idx}/{len(metadata_semantic_model)}] Extracting RLS expressions from '{dataset_name}'...\")\n","    \n","    try:\n","        rls_expression = fabric.get_row_level_security_permissions(\n","            workspace=workspace_name, \n","            dataset=dataset_name\n","        )\n","        \n","        if len(rls_expression) > 0:\n","            # Get role information\n","            role_member = fabric.evaluate_dax(\n","                workspace=workspace_name, \n","                dataset=dataset_name,\n","                dax_string='EVALUATE INFO.ROLES()'\n","            )\n","            role_member.columns = [re.sub(r'[\\[\\]]', '', col) for col in role_member.columns]\n","            \n","            # Combine RLS expressions with role metadata\n","            data_rls = duckdb.query(f'''\n","                WITH list_role_members AS (\n","                    SELECT DISTINCT\n","                        '{dataset_id}' || '-' || CAST(a.ID AS VARCHAR) AS RoleKey,\n","                        '{dataset_id}' AS DatasetID,\n","                        a.ID AS RoleID,\n","                        a.Name AS RoleName\n","                    FROM role_member a\n","                )\n","                SELECT DISTINCT\n","                    {Current_MonthID} AS YearMonth,\n","                    '{workspace_id}' AS WorkspaceID,\n","                    '{workspace_name}' AS WorkspaceName,\n","                    '{dataset_id}' AS DatasetID,\n","                    '{dataset_name}' AS DatasetName,\n","                    b.RoleKey, \n","                    b.RoleID, \n","                    b.RoleName,\n","                    a.Table AS TableName,\n","                    a.\"Filter Expression\" AS FilterExpression,\n","                    CAST('{Current_Datetime}' AS TIMESTAMP) AS ImportTime\n","                FROM rls_expression a \n","                LEFT JOIN list_role_members b ON a.Role = b.RoleName \n","            ''').to_df()\n","            \n","            row_level_security_expression = pd.concat([row_level_security_expression, data_rls], ignore_index=True)\n","            total_rls_rules += len(data_rls)\n","            \n","    except Exception as e:\n","        print(f\"    ‚ö†Ô∏è  No RLS found or access denied: {str(e)[:50]}\")\n","\n","print(f\"‚úÖ Extracted {total_rls_rules} RLS expression(s)\\n\")\n","row_level_security_expression.head(5)"]},{"cell_type":"markdown","id":"f28b299c-fa03-46ac-aa82-72264bacd041","metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"},"nteract":{"transient":{"deleting":false}}},"source":["## 8. Data Refresh History Extraction\n","\n","### Purpose\n","Extract dataset refresh history for the past 14 days to monitor data freshness and identify failures.\n","\n","### Output Fields\n","- **DatasetID**: Semantic model identifier\n","- **RequestID**: Unique refresh request identifier\n","- **StartTime/EndTime**: Refresh timing\n","- **RefreshType**: Full/Incremental/etc.\n","- **Status**: Completed/Failed/In Progress\n","- **ExtendedStatus**: Additional status details\n","- **ServiceExceptionJson**: Error details for failed refreshes\n","- **ImportTime**: Extraction timestamp\n","\n","### Business Value\n","Enables refresh monitoring, SLA tracking, failure alerting, and performance optimization."]},{"cell_type":"code","execution_count":11,"id":"fca7f476-86de-4f84-8a8f-d1c97e4761b9","metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"outputs":[{"data":{"application/vnd.livy.statement-meta+json":{"execution_finish_time":"2025-11-23T14:11:45.6632945Z","execution_start_time":"2025-11-23T14:11:43.8435278Z","livy_statement_state":"available","normalized_state":"finished","parent_msg_id":"6abd5814-2c87-43fa-a8b8-efd7c21b95fc","queued_time":"2025-11-23T14:10:43.5323011Z","session_id":"a88cf86e-dea1-4f0b-8448-815c576e7969","session_start_time":null,"spark_pool":null,"state":"finished","statement_id":13,"statement_ids":[13]},"text/plain":["StatementMeta(, a88cf86e-dea1-4f0b-8448-815c576e7969, 13, Finished, Available, Finished)"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["  [1/3] Extracting refresh history for 'FabricDagsterK1'...\n","    ‚úì Found 0 refresh(es)\n","  [2/3] Extracting refresh history for 'FabircDagsterK1-Cloud'...\n","    ‚úì Found 0 refresh(es)\n","  [3/3] Extracting refresh history for 'Dashboard'...\n","    ‚úì Found 10 refresh(es)\n","\n","‚úÖ Extracted 10 refresh record(s) from 2025-11-09 to 2025-11-23\n","\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>DatasetID</th>\n","      <th>RequestID</th>\n","      <th>StartTime</th>\n","      <th>EndTime</th>\n","      <th>RefreshType</th>\n","      <th>ServiceExceptionJson</th>\n","      <th>Status</th>\n","      <th>ExtendedStatus</th>\n","      <th>ImportTime</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>26ce789d-54a1-4ded-bdc9-de65897d2f8e</td>\n","      <td>c559e7d3-35a9-409a-aedc-d9969f60e3cd</td>\n","      <td>2025-11-22 10:51:28.883000+00:00</td>\n","      <td>2025-11-22 10:51:28.947000+00:00</td>\n","      <td>DirectLakeFraming</td>\n","      <td>None</td>\n","      <td>Completed</td>\n","      <td>None</td>\n","      <td>2025-11-23 21:11:14</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>26ce789d-54a1-4ded-bdc9-de65897d2f8e</td>\n","      <td>bb98f426-bc1e-4997-9aef-e4db731afb88</td>\n","      <td>2025-11-22 10:51:08.883000+00:00</td>\n","      <td>2025-11-22 10:51:10.163000+00:00</td>\n","      <td>DirectLakeFraming</td>\n","      <td>{\"errorCode\":\"Premium_ASWL_Error\",\"errorDescri...</td>\n","      <td>Failed</td>\n","      <td>None</td>\n","      <td>2025-11-23 21:11:14</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>26ce789d-54a1-4ded-bdc9-de65897d2f8e</td>\n","      <td>c4886c85-3cae-4e0e-8e64-74a78235d159</td>\n","      <td>2025-11-22 10:50:58.880000+00:00</td>\n","      <td>2025-11-22 10:50:59.630000+00:00</td>\n","      <td>DirectLakeFraming</td>\n","      <td>{\"errorCode\":\"Premium_ASWL_Error\",\"errorDescri...</td>\n","      <td>Failed</td>\n","      <td>None</td>\n","      <td>2025-11-23 21:11:14</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>26ce789d-54a1-4ded-bdc9-de65897d2f8e</td>\n","      <td>702169ae-7665-4d02-a350-6064e7aaec0a</td>\n","      <td>2025-11-22 10:50:48.880000+00:00</td>\n","      <td>2025-11-22 10:50:49.693000+00:00</td>\n","      <td>DirectLakeFraming</td>\n","      <td>{\"errorCode\":\"Premium_ASWL_Error\",\"errorDescri...</td>\n","      <td>Failed</td>\n","      <td>None</td>\n","      <td>2025-11-23 21:11:14</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>26ce789d-54a1-4ded-bdc9-de65897d2f8e</td>\n","      <td>69fd2d97-cd24-4d3a-ae37-bf13720c6c9b</td>\n","      <td>2025-11-22 10:50:38.880000+00:00</td>\n","      <td>2025-11-22 10:50:40.083000+00:00</td>\n","      <td>DirectLakeFraming</td>\n","      <td>{\"errorCode\":\"Premium_ASWL_Error\",\"errorDescri...</td>\n","      <td>Failed</td>\n","      <td>None</td>\n","      <td>2025-11-23 21:11:14</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                              DatasetID                             RequestID  \\\n","0  26ce789d-54a1-4ded-bdc9-de65897d2f8e  c559e7d3-35a9-409a-aedc-d9969f60e3cd   \n","1  26ce789d-54a1-4ded-bdc9-de65897d2f8e  bb98f426-bc1e-4997-9aef-e4db731afb88   \n","2  26ce789d-54a1-4ded-bdc9-de65897d2f8e  c4886c85-3cae-4e0e-8e64-74a78235d159   \n","3  26ce789d-54a1-4ded-bdc9-de65897d2f8e  702169ae-7665-4d02-a350-6064e7aaec0a   \n","4  26ce789d-54a1-4ded-bdc9-de65897d2f8e  69fd2d97-cd24-4d3a-ae37-bf13720c6c9b   \n","\n","                         StartTime                          EndTime  \\\n","0 2025-11-22 10:51:28.883000+00:00 2025-11-22 10:51:28.947000+00:00   \n","1 2025-11-22 10:51:08.883000+00:00 2025-11-22 10:51:10.163000+00:00   \n","2 2025-11-22 10:50:58.880000+00:00 2025-11-22 10:50:59.630000+00:00   \n","3 2025-11-22 10:50:48.880000+00:00 2025-11-22 10:50:49.693000+00:00   \n","4 2025-11-22 10:50:38.880000+00:00 2025-11-22 10:50:40.083000+00:00   \n","\n","         RefreshType                               ServiceExceptionJson  \\\n","0  DirectLakeFraming                                               None   \n","1  DirectLakeFraming  {\"errorCode\":\"Premium_ASWL_Error\",\"errorDescri...   \n","2  DirectLakeFraming  {\"errorCode\":\"Premium_ASWL_Error\",\"errorDescri...   \n","3  DirectLakeFraming  {\"errorCode\":\"Premium_ASWL_Error\",\"errorDescri...   \n","4  DirectLakeFraming  {\"errorCode\":\"Premium_ASWL_Error\",\"errorDescri...   \n","\n","      Status ExtendedStatus          ImportTime  \n","0  Completed           None 2025-11-23 21:11:14  \n","1     Failed           None 2025-11-23 21:11:14  \n","2     Failed           None 2025-11-23 21:11:14  \n","3     Failed           None 2025-11-23 21:11:14  \n","4     Failed           None 2025-11-23 21:11:14  "]},"execution_count":38,"metadata":{},"output_type":"execute_result"}],"source":["data_refresh_request = pd.DataFrame()\n","total_refreshes = 0\n","\n","for idx, (_, row) in enumerate(metadata_semantic_model.iterrows(), 1):\n","    workspace_name = row[\"WorkspaceName\"]\n","    dataset_name = row[\"DatasetName\"]\n","    dataset_id = row[\"DatasetID\"]\n","    \n","    print(f\"  [{idx}/{len(metadata_semantic_model)}] Extracting refresh history for '{dataset_name}'...\")\n","    \n","    try:\n","        refreshes = fabric.list_refresh_requests(workspace=workspace_name, dataset=dataset_name)\n","        \n","        if len(refreshes) > 0:\n","            # Filter refreshes within date range\n","            refreshes = duckdb.query(f'''\n","                SELECT\n","                    '{dataset_id}' AS DatasetID,\n","                    a.\"Request ID\" AS RequestID,\n","                    a.\"Start Time\" AS StartTime,\n","                    a.\"End Time\" AS EndTime,\n","                    a.\"Refresh Type\" AS RefreshType,\n","                    a.\"Service Exception Json\" AS ServiceExceptionJson,\n","                    a.Status,\n","                    CAST(a.\"Extended Status\" AS VARCHAR) AS ExtendedStatus,\n","                    CAST('{Current_Datetime}' AS TIMESTAMP) AS ImportTime\n","                FROM refreshes a\n","                WHERE CAST(a.\"Start Time\" AS DATE) BETWEEN '{Previous_Date}' AND '{Current_Date}' \n","            ''').to_df()\n","            \n","            data_refresh_request = pd.concat([data_refresh_request, refreshes], ignore_index=True)\n","            total_refreshes += len(refreshes)\n","            print(f\"    ‚úì Found {len(refreshes)} refresh(es)\")\n","            \n","    except Exception as e:\n","        print(f\"    ‚ö†Ô∏è  Failed to retrieve refresh history: {str(e)[:50]}\")\n","\n","print(f\"\\n‚úÖ Extracted {total_refreshes} refresh record(s) from {Previous_Date} to {Current_Date}\\n\")\n","data_refresh_request.head(5)"]},{"cell_type":"markdown","id":"2342813e-1837-4485-a652-016813edfe55","metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"},"nteract":{"transient":{"deleting":false}}},"source":["## 9. Export Data to Lakehouse\n","\n","### Purpose\n","Persist all extracted metadata to Delta Lake tables in Microsoft Fabric Lakehouse for long-term storage, querying, and reporting.\n","\n","### Features\n","- **Batch Export**: Writes all 8 metadata DataFrames to separate Delta tables\n","- **Overwrite Mode**: Refreshes tables completely on each run for idempotency\n","- **Delta Lake Format**: Leverages ACID transactions, schema evolution, and time travel\n","- **Optimized Storage**: Automatic compression and partitioning via Spark\n","\n","### Output Tables\n","\n","| Table Name | Description | Key Fields |\n","|------------|-------------|------------|\n","| `FACT_SemanticModels` | Semantic model inventory | WorkspaceID, DatasetID, DatasetName |\n","| `FACT_Reports` | Power BI reports catalog | ReportID, DatasetID, WebUrl |\n","| `FACT_Measures` | DAX measures repository | DatasetID, Measure, Expression |\n","| `FACT_Relationships` | Table relationship mapping | FromTable, ToTable, Cardinality |\n","| `FACT_Table_Columns` | Complete schema metadata | TableName, ColumnName, DataType |\n","| `FACT_RoleMembers` | Security role assignments | RoleKey, RoleName, MemberName |\n","| `FACT_RLS_Expression` | Row-level security filters | RoleKey, TableName, FilterExpression |\n","| `FACT_DataRefresh` | 14-day refresh history | DatasetID, Status, StartTime |\n","\n","### Business Use Cases\n","1. **Governance Dashboard**: Track all semantic models and their lineage\n","2. **Security Audit**: Monitor RLS roles and member assignments\n","3. **Performance Monitoring**: Analyze refresh patterns and failures\n","4. **Impact Analysis**: Understand report dependencies on datasets\n","5. **Documentation**: Auto-generate data dictionary from schema metadata\n","\n","### Technical Notes\n","- ‚ö†Ô∏è **Prerequisites**: Requires write access to default Lakehouse\n","- üìä **Query Access**: Tables can be queried via SQL Endpoint\n","- üîÑ **Execution**: Run this cell after successful data extraction (cells 1-8)\n","- üíæ **Persistence**: Data persists across notebook sessions\n","- üîç **Schema**: Column names with spaces will cause errors - clean before export if needed"]},{"cell_type":"code","execution_count":32,"id":"b18ce7c0-5569-4073-9a69-805821ff8b6c","metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"outputs":[{"data":{"application/vnd.livy.statement-meta+json":{"execution_finish_time":"2025-11-23T14:26:13.4155597Z","execution_start_time":"2025-11-23T14:25:24.6863267Z","livy_statement_state":"available","normalized_state":"finished","parent_msg_id":"f64fc285-f873-47c7-a011-efa24657d95e","queued_time":"2025-11-23T14:25:24.6847363Z","session_id":"a88cf86e-dea1-4f0b-8448-815c576e7969","session_start_time":null,"spark_pool":null,"state":"finished","statement_id":34,"statement_ids":[34]},"text/plain":["StatementMeta(, a88cf86e-dea1-4f0b-8448-815c576e7969, 34, Finished, Available, Finished)"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/spark/python/lib/pyspark.zip/pyspark/sql/pandas/conversion.py:351: UserWarning: createDataFrame attempted Arrow optimization because 'spark.sql.execution.arrow.pyspark.enabled' is set to true; however, failed by the reason below:\n","  [UNSUPPORTED_DATA_TYPE_FOR_ARROW_CONVERSION] uint64 is not supported in conversion to Arrow.\n","Attempting non-optimization as 'spark.sql.execution.arrow.pyspark.fallback.enabled' is set to true.\n","  warn(msg)\n"]}],"source":["spark.createDataFrame(metadata_semantic_model).write.mode('overwrite').saveAsTable('FACT_SemanticModels')\n","spark.createDataFrame(metadata_report).write.mode('overwrite').saveAsTable('FACT_Reports')\n","spark.createDataFrame(metadata_measures).write.mode('overwrite').saveAsTable('FACT_Measures')\n","spark.createDataFrame(metadata_relationships).write.mode('overwrite').saveAsTable('FACT_Relationships')\n","spark.createDataFrame(metadata_table_columns).write.mode('overwrite').saveAsTable('FACT_Table_Columns')\n","spark.createDataFrame(metadata_role_members).write.mode('overwrite').saveAsTable('FACT_RoleMembers')\n","spark.createDataFrame(row_level_security_expression).write.mode('overwrite').saveAsTable('FACT_RLS_Expression')\n","spark.createDataFrame(data_refresh_request).write.mode('overwrite').saveAsTable('FACT_DataRefresh')"]},{"cell_type":"markdown","id":"6258fcfc-4079-430a-98d0-3305f0679887","metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"},"nteract":{"transient":{"deleting":false}}},"source":["## Summary & Next Steps\n","\n","### Data Extraction Complete ‚úÖ\n","\n","The following metadata has been successfully extracted:\n","\n","1. **Semantic Models**: Dataset inventory and properties\n","2. **Reports**: Report-to-dataset mappings and URLs\n","3. **Measures**: DAX calculations and business logic\n","4. **Tables & Columns**: Complete schema documentation\n","5. **Relationships**: Data model structure\n","6. **Roles & Members**: Security role assignments\n","7. **RLS Expressions**: Row-level security filters\n","8. **Refresh History**: Data refresh monitoring (14-day window)\n","\n","### Output DataFrames Available:\n","- `metadata_semantic_model`\n","- `metadata_report`\n","- `metadata_measures`\n","- `metadata_table_columns`\n","- `metadata_relationships`\n","- `metadata_role_members`\n","- `row_level_security_expression`\n","- `data_refresh_request`\n","\n","### Recommended Next Steps:\n","1. **Export to Data Lake**: Write DataFrames to Delta/Parquet format\n","2. **Load to Database**: Insert into SQL database for querying\n","3. **Create Dashboards**: Build monitoring reports in Power BI\n","4. **Schedule Pipeline**: Automate daily/weekly extraction\n","5. **Implement Alerts**: Set up notifications for refresh failures\n","\n","### Sample Export Code:\n","```python\n","# Export to Parquet\n","metadata_semantic_model.to_parquet('semantic_models.parquet')\n","\n","# Or write to Lakehouse\n","spark.createDataFrame(metadata_semantic_model).write.mode('overwrite').saveAsTable('metadata.semantic_models')\n","```\n"]}],"metadata":{"dependencies":{"lakehouse":{"default_lakehouse":"e6e285ee-0bd4-4e76-8624-568be05a098c","default_lakehouse_name":"Metadata","default_lakehouse_workspace_id":"abf1b960-d04c-4434-9a4d-a84d961dbdad","known_lakehouses":[{"id":"e6e285ee-0bd4-4e76-8624-568be05a098c"}]}},"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"display_name":"PySpark","language":"Python","name":"synapse_pyspark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}}},"nbformat":4,"nbformat_minor":5}