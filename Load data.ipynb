{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0bf5a37b-a084-41e9-8fee-0f6a074ab13f",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "execution_finish_time": "2025-11-22T10:32:43.9552618Z",
       "execution_start_time": "2025-11-22T10:32:38.3428379Z",
       "livy_statement_state": "available",
       "normalized_state": "finished",
       "parent_msg_id": "7909bdee-a2a2-474c-9f1b-461198916691",
       "queued_time": "2025-11-22T10:32:38.3413077Z",
       "session_id": "09402fd4-0f51-4ebe-a20c-6046f9272414",
       "session_start_time": null,
       "spark_pool": null,
       "state": "finished",
       "statement_id": 13,
       "statement_ids": [
        13
       ]
      },
      "text/plain": [
       "StatementMeta(, 09402fd4-0f51-4ebe-a20c-6046f9272414, 13, Finished, Available, Finished)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: office365-REST-Python-Client in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (2.6.2)\r\n",
      "Requirement already satisfied: requests in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (from office365-REST-Python-Client) (2.31.0)\r\n",
      "Requirement already satisfied: msal in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (from office365-REST-Python-Client) (1.25.0)\r\n",
      "Requirement already satisfied: pytz in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (from office365-REST-Python-Client) (2023.3.post1)\r\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (from office365-REST-Python-Client) (4.9.0)\r\n",
      "Requirement already satisfied: PyJWT<3,>=1.0.0 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (from PyJWT[crypto]<3,>=1.0.0->msal->office365-REST-Python-Client) (2.4.0)\r\n",
      "Requirement already satisfied: cryptography<44,>=0.6 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (from msal->office365-REST-Python-Client) (42.0.2)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (from requests->office365-REST-Python-Client) (2.0.4)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (from requests->office365-REST-Python-Client) (3.4)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (from requests->office365-REST-Python-Client) (2.1.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (from requests->office365-REST-Python-Client) (2024.2.2)\r\n",
      "Requirement already satisfied: cffi>=1.12 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (from cryptography<44,>=0.6->msal->office365-REST-Python-Client) (1.16.0)\r\n",
      "Requirement already satisfied: pycparser in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (from cffi>=1.12->cryptography<44,>=0.6->msal->office365-REST-Python-Client) (2.21)\r\n"
     ]
    }
   ],
   "source": [
    "# Welcome to your new notebook\n",
    "# Type here in the cell editor to add code!\n",
    "!pip install office365-REST-Python-Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3cea5f8-0d24-4cad-bed0-f6327c0f0ef9",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "execution_finish_time": "2025-11-22T10:32:44.3371151Z",
       "execution_start_time": "2025-11-22T10:32:43.9593227Z",
       "livy_statement_state": "available",
       "normalized_state": "finished",
       "parent_msg_id": "e8ddf0a4-3f23-428b-9f2c-fce7757c9a81",
       "queued_time": "2025-11-22T10:32:38.5043463Z",
       "session_id": "09402fd4-0f51-4ebe-a20c-6046f9272414",
       "session_start_time": null,
       "spark_pool": null,
       "state": "finished",
       "statement_id": 14,
       "statement_ids": [
        14
       ]
      },
      "text/plain": [
       "StatementMeta(, 09402fd4-0f51-4ebe-a20c-6046f9272414, 14, Finished, Available, Finished)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from office365.sharepoint.client_context import ClientContext\n",
    "from office365.runtime.auth.authentication_context import AuthenticationContext\n",
    "from office365.sharepoint.folders.folder import Folder\n",
    "from office365.sharepoint.files.file import File\n",
    "from office365.sharepoint.sharing.role import Role\n",
    "from office365.sharepoint.sharing.external_site_option import ExternalSharingSiteOption\n",
    "\n",
    "from office365.sharepoint.sharing.internal import sharing_restrictions\n",
    "import io, pandas as pd, tempfile\n",
    "\n",
    "\n",
    "class SharePoint_Connection:\n",
    "    def __init__(self, client_id: str, client_secret: str, team: str) -> None:\n",
    "        \"\"\"\n",
    "        Constructor to initialize SharePoint_Connection object with client_id, client_secret, and team values.\n",
    "\n",
    "        Parameters:\n",
    "            - client_id (str): The client ID used for SharePoint authentication.\n",
    "            - client_secret (str): The client secret used for SharePoint authentication.\n",
    "            - team (str): The name of the SharePoint team.\n",
    "\n",
    "        Returns:\n",
    "            - None\n",
    "        \"\"\"\n",
    "        self.client_id = client_id\n",
    "        self.client_secret = client_secret\n",
    "        self.team = team\n",
    "\n",
    "    def establish_sharepoint_context(self):\n",
    "        \"\"\"\n",
    "        Establishes a SharePoint context using the provided client_id, client_secret, and team.\n",
    "\n",
    "        Parameters:\n",
    "            - self: An instance of the class that contains the method.\n",
    "\n",
    "        Returns:\n",
    "            - ctx (ClientContext): A SharePoint client context established using the provided authentication credentials\n",
    "            (client_id, client_secret) and team information. If successful, the function returns the ClientContext object.\n",
    "            If an error occurs during the establishment of the SharePoint context, an exception is caught and an error message\n",
    "            is printed, and the function returns None.\n",
    "        \"\"\"\n",
    "\n",
    "        try:\n",
    "            # SharePoint site URL based on the company's domain name and team\n",
    "            site_url = f\"https://.sharepoint.com/sites/{self.team}\"\n",
    "            # Authentication context using client_id and client_secret\n",
    "            context_auth = AuthenticationContext(site_url)\n",
    "            # Acquire token for the application\n",
    "            if context_auth.acquire_token_for_app(\n",
    "                client_id=self.client_id, client_secret=self.client_secret\n",
    "            ):\n",
    "                # Create SharePoint client context\n",
    "                ctx = ClientContext(site_url, context_auth)\n",
    "                return ctx\n",
    "        except Exception as e:\n",
    "            # Print error message if an exception occurs during SharePoint context establishment\n",
    "            print(f\"Error: {type(e).__name__} {e}\")\n",
    "            return None\n",
    "        \n",
    "    def folder_details(self, folder_in_sharepoint: str, list_file_input: list):\n",
    "        ctx = self.establish_sharepoint_context()  \n",
    "        folder = ctx.web.get_folder_by_server_relative_url(f\"Shared Documents/{folder_in_sharepoint}\")  \n",
    "        list_file_end = [] \n",
    "        list_file_sharepoint = []\n",
    "        sub_folders = folder.files   \n",
    "        ctx.load(sub_folders)  \n",
    "        ctx.execute_query() \n",
    "        for s_folder in sub_folders:    \n",
    "            list_file_sharepoint.append(s_folder.properties[\"Name\"])\n",
    "\n",
    "        if len(list_file_input) == 0:\n",
    "            list_file_end = list_file_sharepoint\n",
    "        else:\n",
    "            list_file_end = list(set(list_file_sharepoint).intersection(set(list_file_input)))\n",
    "        return list_file_end\n",
    "    \n",
    "    def create_sharepoint_directory(self, directory_name: str) -> str | None:\n",
    "        \"\"\"\n",
    "        Creates a directory in SharePoint under the 'Shared Documents/General/' path.\n",
    "\n",
    "        Parameters:\n",
    "            - directory_name (str): The name of the directory to be created.\n",
    "\n",
    "        Returns:\n",
    "            - str: The relative URL of the created directory if successful. If an error occurs during the creation process,\n",
    "            an error message is printed, and the function returns an empty string.\n",
    "        \"\"\"\n",
    "\n",
    "        if directory_name:\n",
    "            # Establish SharePoint context\n",
    "            ctx = self.establish_sharepoint_context()\n",
    "\n",
    "            # Attempt to create the directory\n",
    "            try:\n",
    "                result = ctx.web.folders.add(\n",
    "                    f\"Shared Documents/{directory_name}\"\n",
    "                ).execute_query()\n",
    "                # If successful, return the relative URL of the created directory\n",
    "                if result:\n",
    "\n",
    "                    relative_url = f\"Shared Documents/{directory_name}\"\n",
    "                    print(\n",
    "                        f\"{directory_name} directory has been created at '{relative_url}'\"\n",
    "                    )\n",
    "                    return relative_url\n",
    "                else:\n",
    "                    print(\"Failed to create a folder/directory!\")\n",
    "                    return \"\"\n",
    "            except Exception as e:\n",
    "                # Print error message if an exception occurs during directory creation\n",
    "                print(f\"Error: {type(e).__name__} {e}\")\n",
    "                return \"\"\n",
    "        else:\n",
    "            print(\"Directory name cannot be empty!\")\n",
    "            return \"\"\n",
    "    \n",
    "    def read_sharepoint_file_as_df(self, file_path: str,sheet_name: str, dtype=None) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Reads a file from SharePoint and returns its content as a Pandas DataFrame.\n",
    "\n",
    "        Parameters:\n",
    "            - file_path (str): The path of the file in SharePoint, relative to the 'Shared Documents' directory.\n",
    "            - dtype (dict or None): Data type specification for columns in the DataFrame (optional).\n",
    "\n",
    "        Returns:\n",
    "            - pd.DataFrame: A Pandas DataFrame containing the content of the specified file. If the 'dtype' parameter is provided,\n",
    "            it is used to specify data types for DataFrame columns during reading.\n",
    "        \"\"\"\n",
    "        # Establish SharePoint context\n",
    "        ctx = self.establish_sharepoint_context()\n",
    "        web = ctx.web\n",
    "        ctx.load(web)\n",
    "        ctx.execute_query()\n",
    "        # Download file content\n",
    "        out = io.BytesIO()\n",
    "        f = (\n",
    "            ctx.web.get_file_by_server_relative_url(f\"/Shared Documents/{file_path}\")\n",
    "            .download(out)\n",
    "            .execute_query()\n",
    "        )\n",
    "        # Read file content into Pandas DataFrame\n",
    "        if dtype is not None:\n",
    "            # If data types are specified, use them during DataFrame creation\n",
    "            # df = pd.read_csv(out, dtype=dtype)\n",
    "            df = pd.read_excel(out, dtype=dtype, sheet_name=sheet_name, engine='openpyxl')\n",
    "        else:\n",
    "            # Otherwise, read the file without specifying data types\n",
    "            # df = pd.read_csv(out)\n",
    "            df = pd.read_excel(out,sheet_name=sheet_name, engine='openpyxl')\n",
    "        # Close the BytesIO stream\n",
    "        out.close()\n",
    "        return df\n",
    "    \n",
    "    def read_sharepoint_csv_as_df(self, file_path: str, dtype=None) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Reads a file from SharePoint and returns its content as a Pandas DataFrame.\n",
    "\n",
    "        Parameters:\n",
    "            - file_path (str): The path of the file in SharePoint, relative to the 'Shared Documents' directory.\n",
    "            - dtype (dict or None): Data type specification for columns in the DataFrame (optional).\n",
    "\n",
    "        Returns:\n",
    "            - pd.DataFrame: A Pandas DataFrame containing the content of the specified file. If the 'dtype' parameter is provided,\n",
    "            it is used to specify data types for DataFrame columns during reading.\n",
    "        \"\"\"\n",
    "        # Establish SharePoint context\n",
    "        ctx = self.establish_sharepoint_context()\n",
    "        web = ctx.web\n",
    "        ctx.load(web)\n",
    "        ctx.execute_query()\n",
    "        # Download file content\n",
    "        out = io.BytesIO()\n",
    "        f = (\n",
    "            ctx.web.get_file_by_server_relative_url(f\"/Shared Documents/{file_path}\")\n",
    "            .download(out)\n",
    "            .execute_query()\n",
    "        )\n",
    "        # Read file content into Pandas DataFrame\n",
    "        if dtype is not None:\n",
    "            # If data types are specified, use them during DataFrame creation\n",
    "            df = pd.read_csv(out, dtype=dtype)\n",
    "            # df = pd.read_excel(out, dtype=dtype\n",
    "        else:\n",
    "            # Otherwise, read the file without specifying data types\n",
    "            df = pd.read_csv(out)\n",
    "            # df = pd.read_excel(out,sheet_name=sheet_name)\n",
    "        # Close the BytesIO stream\n",
    "        out.close()\n",
    "        return df\n",
    "\n",
    "    def write_bytefile_to_sharepoint(\n",
    "        self, file_path: str, file_name: str, file_bytes: bytes\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Writes a byte file to SharePoint in the specified folder with the given file name.\n",
    "\n",
    "        Parameters:\n",
    "            - file_path (str): The path of the folder in SharePoint where the file should be written, relative to the 'Shared Documents' directory.\n",
    "            - file_name (str): The name to be given to the file in SharePoint.\n",
    "            - file_bytes (bytes): The content of the file as a bytes object.\n",
    "\n",
    "        Returns:\n",
    "            - None\n",
    "        \"\"\"\n",
    "        # Establish SharePoint context\n",
    "        ctx = self.establish_sharepoint_context()\n",
    "        # Get the SharePoint folder by server-relative URL\n",
    "        folder: Folder = ctx.web.get_folder_by_server_relative_url(\n",
    "            f\"Shared Documents/{file_path}\"\n",
    "        )\n",
    "        # Chunk size for uploading\n",
    "        chunk_size: int = 500000\n",
    "\n",
    "        # Check if the file already exists\n",
    "        file: File = folder.files.get_by_url(file_name)\n",
    "\n",
    "        if file.exists:\n",
    "\n",
    "            # If the file exists, delete it\n",
    "            file.delete_object().execute_query()\n",
    "\n",
    "        # Create a temporary file and write the bytes to it\n",
    "        with tempfile.NamedTemporaryFile(delete=False) as temp_file:\n",
    "            temp_file.write(file_bytes)\n",
    "\n",
    "        # Use the temporary file for uploading\n",
    "        with open(temp_file.name, \"rb\") as file_to_upload:\n",
    "            folder.files.create_upload_session(\n",
    "                file=file_to_upload, chunk_size=chunk_size, file_name=file_name\n",
    "            ).execute_query()\n",
    "        # Print success message\n",
    "        print(f\"{file_name} has been uploaded successfully!\")\n",
    "\n",
    "    \n",
    "    def grant_users(\n",
    "        self, folder_in_sharepoint: str, email: str, role: str\n",
    "    ) -> None:\n",
    "        '''\n",
    "            Grants permission to a user for a specific folder in SharePoint.\n",
    "\n",
    "            This method establishes a SharePoint context and grants the specified \n",
    "            permission (e.g., 'View' or 'Edit') to a user for a target folder located \n",
    "            under 'Shared Documents'.\n",
    "\n",
    "    \n",
    "            - folder_in_sharepoint (str): The relative path to the folder within \n",
    "                'Shared Documents' where access should be granted.\n",
    "            - email (str): The email address of the user to be granted access.\n",
    "            - role (str): The level of access to grant. Acceptable values include \n",
    "                'View' or 'Edit'.\n",
    "        '''\n",
    "        ctx = self.establish_sharepoint_context()\n",
    "        folder_url = f\"Shared Documents/{folder_in_sharepoint}\"\n",
    "        folder = ctx.web.get_folder_by_server_relative_url(folder_url)\n",
    "        folder_item = folder.list_item_all_fields\n",
    "        ctx.load(folder_item)\n",
    "        ctx.execute_query()\n",
    "\n",
    "        # 4. Gọi chia sẻ\n",
    "        try:\n",
    "            result = folder_item.share(\n",
    "            \n",
    "                user_principal_name=email,\n",
    "                share_option = ExternalSharingSiteOption.View if role == \"View\" else ExternalSharingSiteOption.Edit,\n",
    "                send_email=True,\n",
    "                email_subject=f\"Grant Access to Folder: {folder_in_sharepoint}\",\n",
    "                email_body=f\"You have been granted '{role}' access to the folder '{folder_in_sharepoint}'. Click the link to access it.\"\n",
    "            )\n",
    "\n",
    "            ctx.execute_query()\n",
    "            print(f\"✅ Đã chia sẻ '{role}' tới: {email}\")\n",
    "\n",
    "\n",
    "      \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Lỗi khi chia sẻ tới {email}: {str(e)}\")\n",
    "\n",
    "\n",
    "    def share_link(\n",
    "        self, folder_in_sharepoint: str\n",
    "    ) -> None:\n",
    "        '''\n",
    "            role: View, Edit\n",
    "        '''\n",
    "        ctx = self.establish_sharepoint_context()\n",
    "        folder_url = f\"Shared Documents/{folder_in_sharepoint}\"\n",
    "        folder = ctx.web.get_folder_by_server_relative_url(folder_url)\n",
    "\n",
    "\n",
    "        a = folder.get_sharing_information()\n",
    "\n",
    "        print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c9d83b5d-bda3-428a-bdf9-21ba0a8f4b03",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "execution_finish_time": "2025-11-22T10:32:44.7410751Z",
       "execution_start_time": "2025-11-22T10:32:44.3400378Z",
       "livy_statement_state": "available",
       "normalized_state": "finished",
       "parent_msg_id": "6f1ed99c-4b46-4917-bb79-6ee472689868",
       "queued_time": "2025-11-22T10:32:38.827345Z",
       "session_id": "09402fd4-0f51-4ebe-a20c-6046f9272414",
       "session_start_time": null,
       "spark_pool": null,
       "state": "finished",
       "statement_id": 15,
       "statement_ids": [
        15
       ]
      },
      "text/plain": [
       "StatementMeta(, 09402fd4-0f51-4ebe-a20c-6046f9272414, 15, Finished, Available, Finished)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import getpass\n",
    "import pyspark\n",
    "importing_user = getpass.getuser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb62c9d5-fbd9-4eef-8ffe-33c312afddd0",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "execution_finish_time": "2025-11-22T10:32:45.1381397Z",
       "execution_start_time": "2025-11-22T10:32:44.7440524Z",
       "livy_statement_state": "available",
       "normalized_state": "finished",
       "parent_msg_id": "ba246daf-ed6b-4906-97bc-7eefb9a1a945",
       "queued_time": "2025-11-22T10:32:39.0227157Z",
       "session_id": "09402fd4-0f51-4ebe-a20c-6046f9272414",
       "session_start_time": null,
       "spark_pool": null,
       "state": "finished",
       "statement_id": 16,
       "statement_ids": [
        16
       ]
      },
      "text/plain": [
       "StatementMeta(, 09402fd4-0f51-4ebe-a20c-6046f9272414, 16, Finished, Available, Finished)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import requests\n",
    "def send_workflow(text):\n",
    "    workflow_url = 'https://prod-26.southeastasia.logic.azure.com:443/workflows/'\n",
    "    payload = {\n",
    "        \"type\": \"message\",\n",
    "        \"text\": text\n",
    "    }\n",
    "    response = requests.post(workflow_url, json=payload)\n",
    "    if response.status_code == 200:\n",
    "        print(\"Webhook sent successfully!\")\n",
    "    elif response.status_code == 202:\n",
    "        print(\"Webhook accepted for processing!\")\n",
    "    else:\n",
    "        print(f\"Failed to send webhook. Status code: {response.status_code}\")\n",
    "        \n",
    "        print(\"Response content:\", response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47f499d-c16f-444e-82f0-c60ef2260001",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "execution_finish_time": "2025-11-22T10:32:45.5109173Z",
       "execution_start_time": "2025-11-22T10:32:45.1411036Z",
       "livy_statement_state": "available",
       "normalized_state": "finished",
       "parent_msg_id": "344dd223-4149-4d50-beec-e0a9a17a4ffb",
       "queued_time": "2025-11-22T10:32:39.2392061Z",
       "session_id": "09402fd4-0f51-4ebe-a20c-6046f9272414",
       "session_start_time": null,
       "spark_pool": null,
       "state": "finished",
       "statement_id": 17,
       "statement_ids": [
        17
       ]
      },
      "text/plain": [
       "StatementMeta(, 09402fd4-0f51-4ebe-a20c-6046f9272414, 17, Finished, Available, Finished)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "CLIENT_ID = 'd0635947-8f06-4353'\n",
    "CLIENT_SECRET = 'RXFOOFF+RnM5Sml4RHcyZW1Cg=='\n",
    "TEAM = 'DagsterAndFabric'\n",
    "\n",
    "connection = SharePoint_Connection(CLIENT_ID, CLIENT_SECRET, TEAM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "140672e8-693e-4122-930b-667119e94550",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "execution_finish_time": "2025-11-22T10:32:46.5034581Z",
       "execution_start_time": "2025-11-22T10:32:45.5137819Z",
       "livy_statement_state": "available",
       "normalized_state": "finished",
       "parent_msg_id": "b0446054-2e3c-43a0-8620-fdff8d924fa6",
       "queued_time": "2025-11-22T10:32:39.4195142Z",
       "session_id": "09402fd4-0f51-4ebe-a20c-6046f9272414",
       "session_start_time": null,
       "spark_pool": null,
       "state": "finished",
       "statement_id": 18,
       "statement_ids": [
        18
       ]
      },
      "text/plain": [
       "StatementMeta(, 09402fd4-0f51-4ebe-a20c-6046f9272414, 18, Finished, Available, Finished)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['fact.xlsx', 'dim_date.xlsx', 'dim_store.xlsx', 'dim_customer.xlsx']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder_shapoint_path = 'Tutram'\n",
    "list_file = []\n",
    "connection.folder_details(folder_shapoint_path, list_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "22dd2a48-e865-45f0-a029-9b87b2792b0a",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "execution_finish_time": "2025-11-22T10:32:46.9298836Z",
       "execution_start_time": "2025-11-22T10:32:46.5069099Z",
       "livy_statement_state": "available",
       "normalized_state": "finished",
       "parent_msg_id": "56303c38-7509-49df-866d-e863cba367bf",
       "queued_time": "2025-11-22T10:32:39.6319471Z",
       "session_id": "09402fd4-0f51-4ebe-a20c-6046f9272414",
       "session_start_time": null,
       "spark_pool": null,
       "state": "finished",
       "statement_id": 19,
       "statement_ids": [
        19
       ]
      },
      "text/plain": [
       "StatementMeta(, 09402fd4-0f51-4ebe-a20c-6046f9272414, 19, Finished, Available, Finished)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Dictionary cho các bảng dimension ---\n",
    "dim_file_dictionary = {\n",
    "    'Date': \"Tutram/dim_date.xlsx\",\n",
    "    'Store': \"Tutram/dim_store.xlsx\",\n",
    "    'Customer': \"Tutram/dim_customer.xlsx\"\n",
    "}\n",
    "\n",
    "# --- Dictionary cho bảng fact ---\n",
    "fact_file_dictionary = {\n",
    "    'Sales': \"Tutram/fact.xlsx\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "032cd4ab-832e-4335-9aee-a6b9bc56e7b4",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "execution_finish_time": "2025-11-22T10:32:47.3445634Z",
       "execution_start_time": "2025-11-22T10:32:46.9327132Z",
       "livy_statement_state": "available",
       "normalized_state": "finished",
       "parent_msg_id": "34ce5c6b-77f5-47c4-8b19-c696fbc3db8c",
       "queued_time": "2025-11-22T10:32:39.8254832Z",
       "session_id": "09402fd4-0f51-4ebe-a20c-6046f9272414",
       "session_start_time": null,
       "spark_pool": null,
       "state": "finished",
       "statement_id": 20,
       "statement_ids": [
        20
       ]
      },
      "text/plain": [
       "StatementMeta(, 09402fd4-0f51-4ebe-a20c-6046f9272414, 20, Finished, Available, Finished)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "spark.conf.set(\"spark.sql.execution.arrow.pyspark.enabled\", \"false\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ae8403b0-a335-4345-b322-211e12503184",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "execution_finish_time": "2025-11-22T10:34:50.7081333Z",
       "execution_start_time": "2025-11-22T10:32:47.3471425Z",
       "livy_statement_state": "available",
       "normalized_state": "finished",
       "parent_msg_id": "6ad5bf90-dc37-4935-b7f8-f1044afe3c5b",
       "queued_time": "2025-11-22T10:32:39.9928099Z",
       "session_id": "09402fd4-0f51-4ebe-a20c-6046f9272414",
       "session_start_time": null,
       "spark_pool": null,
       "state": "finished",
       "statement_id": 21,
       "statement_ids": [
        21
       ]
      },
      "text/plain": [
       "StatementMeta(, 09402fd4-0f51-4ebe-a20c-6046f9272414, 21, Finished, Available, Finished)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Processing Sales: Tutram/fact.xlsx\n",
      "✅ Transform Sales with 1048575 rows successfully\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i = 1\n",
    "for table_name, path_file in fact_file_dictionary.items():\n",
    "    print(f\"{i}. Processing {table_name}: {path_file}\")\n",
    "    df = connection.read_sharepoint_file_as_df(path_file, 'Sheet1')\n",
    "    # Thêm metadata\n",
    "    df['FilePath'] = path_file\n",
    "    df['User'] = importing_user\n",
    "    # Nếu có cột 'transaction_time' thì chuẩn hoá (phòng trường hợp có)\n",
    "    if 'transaction_time' in df.columns:\n",
    "        df[\"transaction_time\"] = (\n",
    "            pd.to_timedelta(df[\"transaction_time\"].astype(str).str.strip())\n",
    "            .dt.total_seconds()\n",
    "        )\n",
    "    # Tạo Spark DataFrame\n",
    "    spark_df = spark.createDataFrame(df)\n",
    "    # Ghi dữ liệu vào Delta Table\n",
    "    spark_df.write.format(\"delta\") \\\n",
    "        .mode(\"overwrite\") \\\n",
    "        .option(\"overwriteSchema\", \"true\") \\\n",
    "        .saveAsTable(f'FACT_{table_name.upper()}')\n",
    "    print(f\"✅ Transform {table_name} with {spark_df.count()} rows successfully\\n\")\n",
    "    i += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "218d66c3-9399-4ffb-93b0-0912d0896a3e",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "execution_finish_time": "2025-11-22T10:35:57.7882497Z",
       "execution_start_time": "2025-11-22T10:34:50.7115542Z",
       "livy_statement_state": "available",
       "normalized_state": "finished",
       "parent_msg_id": "f800c005-eb61-4f0f-86fa-ac521493c952",
       "queued_time": "2025-11-22T10:32:40.1145533Z",
       "session_id": "09402fd4-0f51-4ebe-a20c-6046f9272414",
       "session_start_time": null,
       "spark_pool": null,
       "state": "finished",
       "statement_id": 22,
       "statement_ids": [
        22
       ]
      },
      "text/plain": [
       "StatementMeta(, 09402fd4-0f51-4ebe-a20c-6046f9272414, 22, Finished, Available, Finished)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Processing DIM_Date: Tutram/dim_date.xlsx\n",
      "✅ Transform DIM_Date with 466 rows successfully\n",
      "\n",
      "2. Processing DIM_Store: Tutram/dim_store.xlsx\n",
      "✅ Transform DIM_Store with 135 rows successfully\n",
      "\n",
      "3. Processing DIM_Customer: Tutram/dim_customer.xlsx\n",
      "✅ Transform DIM_Customer with 583642 rows successfully\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i = 1\n",
    "for table_name, path_file in dim_file_dictionary.items():\n",
    "    print(f\"{i}. Processing DIM_{table_name}: {path_file}\")\n",
    "    # Đọc dữ liệu từ SharePoint (sheet 'data' hoặc 'Sheet1' tùy file)\n",
    "    df = connection.read_sharepoint_file_as_df(path_file, 'Sheet1')\n",
    "    # Thêm metadata\n",
    "    df['FilePath'] = path_file\n",
    "    df['User'] = importing_user\n",
    "    # Tạo Spark DataFrame từ Pandas DataFrame\n",
    "    spark_df = spark.createDataFrame(df)\n",
    "    # Ghi dữ liệu vào Delta Table trong Lakehouse\n",
    "    spark_df.write.format(\"delta\") \\\n",
    "        .mode(\"overwrite\") \\\n",
    "        .option(\"overwriteSchema\", \"true\") \\\n",
    "        .saveAsTable(f'DIM_{table_name.upper()}')\n",
    "    print(f\"✅ Transform DIM_{table_name} with {spark_df.count()} rows successfully\\n\")\n",
    "    i += 1"
   ]
  }
 ],
 "metadata": {
  "dependencies": {
   "lakehouse": {
    "default_lakehouse": "4d2bbc9f-3380-4270-a9b2-9c0fe76c7d7e",
    "default_lakehouse_name": "FabricStaging",
    "default_lakehouse_workspace_id": "abf1b960-d04c-4434-9a4d-a84d961dbdad",
    "known_lakehouses": [
     {
      "id": "4d2bbc9f-3380-4270-a9b2-9c0fe76c7d7e"
     }
    ]
   }
  },
  "kernel_info": {
   "name": "synapse_pyspark"
  },
  "kernelspec": {
   "display_name": "synapse_pyspark",
   "name": "synapse_pyspark"
  },
  "language_info": {
   "name": "python"
  },
  "microsoft": {
   "language": "python",
   "language_group": "synapse_pyspark",
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "spark_compute": {
   "compute_id": "/trident/default",
   "session_options": {
    "conf": {
     "spark.synapse.nbs.session.timeout": "1200000"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
